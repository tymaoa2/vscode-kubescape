{
  "guid": "",
  "name": "cis-aks-t1.2.0",
  "attributes": {
    "armoBuiltin": true,
    "version": "v1.2.0"
  },
  "creationTime": "",
  "description": "Testing CIS for Azure Kubernetes Service (AKS) as suggested by CIS benchmark: https://workbench.cisecurity.org/benchmarks/9058",
  "controls": [
    {
      "rulesIDs": [
        "",
        ""
      ],
      "guid": "",
      "name": "CIS-5.1.4 Minimize Container Registries to only those approved",
      "attributes": {
        "actionRequired": "configuration",
        "microsoftMitreColumns": [
          "Collection"
        ],
        "controlTypeTags": [
          "security",
          "compliance"
        ]
      },
      "controlID": "C-0078",
      "creationTime": "",
      "description": "Use approved container registries.",
      "remediation": "If you are using Azure Container Registry you have this option:<https://docs.microsoft.com/en-us/azure/container-registry/container-registry-firewall-access-rules>\n\n For other non-AKS repos using admission controllers or Azure Policy will also work.\n\n Limiting or locking down egress traffic is also recommended:\n<https://docs.microsoft.com/en-us/azure/aks/limit-egress-traffic>",
      "rules": [
        {
          "guid": "",
          "name": "container-image-repository",
          "attributes": {
            "m$K8sThreatMatrix": "Collection::Images from private registry",
            "useUntilKubescapeVersion": "v2.3.8"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.if\n\nuntrusted_image_repo[msga] {\n\tpod := input[_]\n\tpod.kind == \"Pod\"\n\tcontainer := pod.spec.containers[i]\n\timage := container.image\n\tnot image_in_allowed_list(image)\n\tpath := sprintf(\"spec.containers[%v].image\", [format_int(i, 10)])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"image '%v' in container '%s' comes from untrusted registry\", [image, container.name]),\n\t\t\"alertScore\": 2,\n        \"packagename\": \"armo_builtins\",\n\t\t\"reviewPaths\": [path],\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\":[],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\nuntrusted_image_repo[msga] {\n\twl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\tcontainer := wl.spec.template.spec.containers[i]\n\timage := container.image\n    not image_in_allowed_list(image)\n\n\tpath := sprintf(\"spec.template.spec.containers[%v].image\", [format_int(i, 10)])\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"image '%v' in container '%s' comes from untrusted registry\", [image, container.name]),\n\t\t\"alertScore\": 2,\n        \"packagename\": \"armo_builtins\",\n\t\t\"reviewPaths\": [path],\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\":[],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\nuntrusted_image_repo[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer := wl.spec.jobTemplate.spec.template.spec.containers[i]\n\timage := container.image\n    not image_in_allowed_list(image)\n\n\tpath := sprintf(\"spec.jobTemplate.spec.template.spec.containers[%v].image\", [format_int(i, 10)])\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"image '%v' in container '%s' comes from untrusted registry\", [image, container.name]),\n\t\t\"alertScore\": 2,\n        \"packagename\": \"armo_builtins\",\n\t\t\"reviewPaths\": [path],\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\":[],\n\t\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# image_in_allowed_list - rule to check if an image complies with imageRepositoryAllowList.\nimage_in_allowed_list(image){\n\n\t# see default-config-inputs.json for list values\n\tallowedlist := data.postureControlInputs.imageRepositoryAllowList\n\tregistry := allowedlist[_]\n\n\tregex.match(regexify(registry), docker_host_wrapper(image))\n}\n\n\n# docker_host_wrapper - wrap an image without a host with a docker hub host 'docker.io'.\n# An image that doesn't contain '/' is assumed to not having a host and therefore associated with docker hub.\ndocker_host_wrapper(image) := result if {\n\tnot contains(image, \"/\")\n\tresult := sprintf(\"docker.io/%s\", [image])\n} else := image\n\n\n# regexify - returns a registry regex to be searched only for the image host.\nregexify(registry) := result {\n\tendswith(registry, \"/\")\n\tresult = sprintf(\"^%s.*$\", [registry])\n} else := sprintf(\"^%s\\/.*$\", [registry])\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": [
            "settings.postureControlInputs.imageRepositoryAllowList"
          ],
          "controlConfigInputs": [
            {
              "path": "settings.postureControlInputs.imageRepositoryAllowList",
              "name": "Allowed image repositories",
              "description": "Kubescape checks that all container images are from repositories explicitly allowed in this list."
            }
          ],
          "description": "Fails if image is not from allowed repository",
          "remediation": "",
          "ruleQuery": "",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "container-image-repository-v1",
          "attributes": {
            "m$K8sThreatMatrix": "Collection::Images from private registry",
            "useFromKubescapeVersion": "v2.9.0"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nuntrustedImageRepo[msga] {\n\twl := input[_]\n\tcontainers_path := get_containers_path(wl)\n\tcontainers := object.get(wl, containers_path, [])\n\tcontainer := containers[i]\n\tname := image.parse_normalized_name(container.image)\n\tnot image_in_allowed_list(name)\n\tpath := sprintf(\"%s[%d].image\", [concat(\".\", containers_path), i])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"image '%v' in container '%s' comes from untrusted registry\", [name, container.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 2,\n\t\t\"fixPaths\": [],\n\t\t\"reviewPaths\": [path],\n\t\t\"failedPaths\": [path],\n\t\t\"alertObject\": {\"k8sApiObjects\": [wl]},\n\t}\n}\n\n# image_in_allowed_list - rule to check if an image complies with imageRepositoryAllowList.\nimage_in_allowed_list(image){\n\t# see default-config-inputs.json for list values\n\tallowedlist := data.postureControlInputs.imageRepositoryAllowList\n\tregistry := allowedlist[_]\n\tstartswith(image, registry)\n}\n\n# get_containers_path - get resource containers paths for  {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\nget_containers_path(resource) := result {\n\tresource_kinds := {\"Deployment\", \"ReplicaSet\", \"DaemonSet\", \"StatefulSet\", \"Job\"}\n\tresource_kinds[resource.kind]\n\tresult = [\"spec\", \"template\", \"spec\", \"containers\"]\n}\n\n# get_containers_path - get resource containers paths for \"Pod\"\nget_containers_path(resource) := result {\n\tresource.kind == \"Pod\"\n\tresult = [\"spec\", \"containers\"]\n}\n\n# get_containers_path - get resource containers paths for  \"CronJob\"\nget_containers_path(resource) := result {\n\tresource.kind == \"CronJob\"\n\tresult = [\"spec\", \"jobTemplate\", \"spec\", \"template\", \"spec\", \"containers\"]\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": [
            "settings.postureControlInputs.imageRepositoryAllowList"
          ],
          "controlConfigInputs": [
            {
              "path": "settings.postureControlInputs.imageRepositoryAllowList",
              "name": "Allowed image repositories",
              "description": "Kubescape checks that all container images are from repositories explicitly allowed in this list."
            }
          ],
          "description": "Fails if image is not from allowed repository",
          "remediation": "",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 5
    },
    {
      "rulesIDs": [
        "",
        ""
      ],
      "guid": "",
      "name": "CIS-5.5.1 Manage Kubernetes RBAC users with Azure AD",
      "attributes": {
        "controlTypeTags": [
          "security",
          "compliance"
        ]
      },
      "controlID": "C-0088",
      "creationTime": "",
      "description": "Azure Kubernetes Service (AKS) can be configured to use Azure Active Directory (AD) for user authentication. In this configuration, you sign in to an AKS cluster using an Azure AD authentication token. You can also configure Kubernetes role-based access control (Kubernetes RBAC) to limit access to cluster resources based a user's identity or group membership.",
      "remediation": "Enable RBAC either in the API server configuration or with the Kubernetes provider API",
      "rules": [
        {
          "guid": "",
          "name": "rbac-enabled-cloud",
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n\tcluster_config := input[_]\n\tcluster_config.apiVersion == \"management.azure.com/v1\"\n\tcluster_config.kind == \"ClusterDescribe\"\n\tcluster_config.metadata.provider == \"aks\"\n\tconfig := cluster_config.data\n\tnot config.properties.enableRBAC == true\n\n\tmsga := {\n\t\t\"alertMessage\": \"rbac is not enabled\",\n\t\t\"alertScore\": 3,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"reviewPaths\": [\"data.properties.enableRBAC\"],\n\t\t\"failedPaths\": [\"data.properties.enableRBAC\"],\n\t\t\"fixCommand\": \"\",\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n            \t\t\"externalObjects\": cluster_config\n\t\t}\n\t}\n}\n\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "management.azure.com"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ClusterDescribe"
              ]
            },
            {
              "apiGroups": [
                "container.googleapis.com"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ClusterDescribe"
              ]
            },
            {
              "apiGroups": [
                "eks.amazonaws.com"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ClusterDescribe"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": [
            "AKS",
            "EKS",
            "GKE"
          ]
        },
        {
          "guid": "",
          "name": "rbac-enabled-native",
          "attributes": {
            "resourcesAggregator": "apiserver-pod",
            "useFromKubescapeVersion": "v1.0.133"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n\n# Check if psp is enabled for native k8s\ndeny[msga] {\n\tapiserverpod := input[_]\n    cmd := apiserverpod.spec.containers[0].command[j]\n    contains(cmd, \"--authorization-mode=\")\n    output := split(cmd, \"=\")\n    not contains(output[1], \"RBAC\")\n\tpath := sprintf(\"spec.containers[0].command[%v]\", [format_int(j, 10)])\t\n\t\n\tmsga := {\n\t\t\"alertMessage\": \"RBAC is not enabled\",\n\t\t\"alertScore\": 9,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"reviewPaths\": [path],\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [apiserverpod],\n\t\t}\n\t}\n}",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 7
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-3.1.2 Ensure that the kubelet kubeconfig file ownership is set to root:root",
      "controlID": "C-0167",
      "creationTime": "",
      "description": "If `kubelet` is running, ensure that the file ownership of its kubeconfig file is set to `root:root`.",
      "remediation": "Run the below command (based on the file location on your system) on each worker node. For example,\n\n \n```\nchown root:root <proxy kubeconfig file>\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-kubeconfig-kubelet.conf-file-ownership-is-set-to-root-root",
          "attributes": {
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\nimport data.cautils\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_kubelet_info(obj)\n\n\tfile_obj_path := [\"data\", \"kubeConfigFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual ownership check\n\tallowed_user := \"root\"\n\tallowed_group := \"root\"\n\tnot allowed_ownership(file.ownership, allowed_user, allowed_group)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"%s is not owned by %s:%s (actual owners are %s:%s)\", [\n\t\tfile.path,\n\t\tallowed_user,\n\t\tallowed_group,\n\t\tfile.ownership.username,\n\t\tfile.ownership.groupname,\n\t])\n\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chown %s:%s %s\", [allowed_user, allowed_group, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"KubeletInfo\"\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.error # Do not fail if ownership is not found\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.username == user\n\townership.groupname == group\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the `kubelet.conf` file ownership is set to `root:root`.",
          "remediation": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n \n```\nchown root:root /etc/kubernetes/kubelet.conf\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 6
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-3.1.4 Ensure that the kubelet configuration file ownership is set to root:root",
      "controlID": "C-0171",
      "creationTime": "",
      "description": "Ensure that if the kubelet refers to a configuration file with the `--config` argument, that file is owned by root:root.",
      "remediation": "Run the following command (using the config file location identified in the Audit step)\n\n \n```\nchown root:root /etc/kubernetes/kubelet/kubelet-config.json\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-kubelet-configuration-file-ownership-is-set-to-root-root",
          "attributes": {
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\nimport data.cautils\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_kubelet_info(obj)\n\n\tfile_obj_path := [\"data\", \"configFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual ownership check\n\tallowed_user := \"root\"\n\tallowed_group := \"root\"\n\tnot allowed_ownership(file.ownership, allowed_user, allowed_group)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"%s is not owned by %s:%s (actual owners are %s:%s)\", [\n\t\tfile.path,\n\t\tallowed_user,\n\t\tallowed_group,\n\t\tfile.ownership.username,\n\t\tfile.ownership.groupname,\n\t])\n\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chown %s:%s %s\", [allowed_user, allowed_group, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"KubeletInfo\"\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.error # Do not fail if ownership is not found\n}\n\nallowed_ownership(ownership, user, group) {\n\townership.username == user\n\townership.groupname == group\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that if the kubelet refers to a configuration file with the `--config` argument, that file is owned by root:root.",
          "remediation": "Run the following command (using the config file location identied in the Audit step)\n\n \n```\nchown root:root /etc/kubernetes/kubelet.conf\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 7
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-3.2.1 Ensure that the --anonymous-auth argument is set to false",
      "controlID": "C-0172",
      "creationTime": "",
      "description": "Disable anonymous requests to the Kubelet server.",
      "remediation": "**Remediation Method 1:**\n\n If modifying the Kubelet config file, edit the kubelet-config.json file `/etc/kubernetes/kubelet/kubelet-config.json` and set the below parameter to false\n\n \n```\n\"anonymous\": \"enabled\": false\n\n```\n **Remediation Method 2:**\n\n If using executable arguments, edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` on each worker node and add the below parameter at the end of the `KUBELET_ARGS` variable string.\n\n \n```\n--anonymous-auth=false\n\n```\n **Remediation Method 3:**\n\n If using the api configz endpoint consider searching for the status of `\"authentication.*anonymous\":{\"enabled\":false}\"` by extracting the live configuration from the nodes running kubelet.\\*\\*See detailed step-by-step configmap procedures in[Reconfigure a Node's Kubelet in a Live Cluster](https://kubernetes.io/docs/tasks/administer-cluster/reconfigure-kubelet/), and then rerun the curl statement from audit process to check for kubelet configuration changes\n\n \n```\nkubectl proxy --port=8001 &\n\nexport HOSTNAME_PORT=localhost:8001 (example host and port number)\nexport NODE_NAME=ip-192.168.31.226.aks.internal (example node name from \"kubectl get nodes\")\n\ncurl -sSL \"http://${HOSTNAME_PORT}/api/v1/nodes/${NODE_NAME}/proxy/configz\"\n\n```\n **For all three remediations:**\nBased on your system, restart the `kubelet` service and check status\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\nsystemctl status kubelet -l\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "anonymous-requests-to-kubelet-service-updated",
          "attributes": {
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n# CIS 4.2.1 https://workbench.cisecurity.org/sections/1126668/recommendations/1838638\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\tcommand := obj.data.cmdLine\n\n\tcontains(command, \"--anonymous-auth\")\n\tcontains(command, \"--anonymous-auth=true\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Anonymous requests is enabled.\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--anonymous-auth\")\n\tnot contains(command, \"--config\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Anonymous requests is enabled.\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--anonymous-auth\")\n\tcontains(command, \"--config\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\tnot yamlConfig.authentication.anonymous.enabled == false\n\n\tmsga := {\n\t\t\"alertMessage\": \"Anonymous requests is enabled.\",\n\t\t\"alertScore\": 7,\n\t\t\"reviewPaths\": [\"authentication.anonymous.enabled\"],\n\t\t\"failedPaths\": [\"authentication.anonymous.enabled\"],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}},\n\t}\n}\n\n## Host sensor failed to get config file content\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--anonymous-auth\")\n\tcontains(command, \"--config\")\n\n\tnot obj.data.configFile.content\n\n\tmsga := {\n\t\t\"alertMessage\": \"Failed to analyze config file\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": obj.data,\n\t\t}},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Determines if anonymous requests to the kubelet service are allowed.",
          "remediation": "Disable anonymous requests by setting  the anonymous-auth flag to false, or using the kubelet configuration file.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 7
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-3.2.2 Ensure that the --authorization-mode argument is not set to AlwaysAllow",
      "controlID": "C-0173",
      "creationTime": "",
      "description": "Do not allow all requests. Enable explicit authorization.",
      "remediation": "**Remediation Method 1:**\n\n If modifying the Kubelet config file, edit the kubelet-config.json file `/etc/kubernetes/kubelet/kubelet-config.json` and set the below parameter to false\n\n \n```\n\"authentication\"... \"webhook\":{\"enabled\":true\n\n```\n **Remediation Method 2:**\n\n If using executable arguments, edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` on each worker node and add the below parameter at the end of the `KUBELET_ARGS` variable string.\n\n \n```\n--authorization-mode=Webhook\n\n```\n **Remediation Method 3:**\n\n If using the api configz endpoint consider searching for the status of `\"authentication.*webhook\":{\"enabled\":true\"` by extracting the live configuration from the nodes running kubelet.\n\n \\*\\*See detailed step-by-step configmap procedures in [Reconfigure a Node's Kubelet in a Live Cluster](https://kubernetes.io/docs/tasks/administer-cluster/reconfigure-kubelet/), and then rerun the curl statement from audit process to check for kubelet configuration changes\n\n \n```\nkubectl proxy --port=8001 &\n\nexport HOSTNAME_PORT=localhost:8001 (example host and port number)\nexport NODE_NAME=ip-192.168.31.226.aks.internal (example node name from \"kubectl get nodes\")\n\ncurl -sSL \"http://${HOSTNAME_PORT}/api/v1/nodes/${NODE_NAME}/proxy/configz\"\n\n```\n **For all three remediations:**\nBased on your system, restart the `kubelet` service and check status\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\nsystemctl status kubelet -l\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "kubelet-authorization-mode-alwaysAllow",
          "attributes": {
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# CIS 4.2.2 https://workbench.cisecurity.org/sections/1126668/recommendations/1838640\n\n# has cli\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tcontains(command, \"--authorization-mode\")\n\tcontains(command, \"--authorization-mode=AlwaysAllow\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Anonymous requests are enabled\",\n\t\t\"alertScore\": 10,\n\t\t\"reviewPaths\": [],\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\n# has config\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--authorization-mode\")\n\tcontains(command, \"--config\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\tyamlConfig.authorization.mode == \"AlwaysAllow\"\n\n\tmsga := {\n\t\t\"alertMessage\": \"Anonymous requests are enabled\",\n\t\t\"alertScore\": 10,\n\t\t\"reviewPaths\": [\"authorization.mode\"],\n\t\t\"failedPaths\": [\"authorization.mode\"],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}},\n\t}\n}\n\n# has no config and cli\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--authorization-mode\")\n\tnot contains(command, \"--config\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\tmsga := {\n\t\t\"alertMessage\": \"Anonymous requests are enabled\",\n\t\t\"alertScore\": 10,\n\t\t\"reviewPaths\": [],\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\n## Host sensor failed to get config file content\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--authorization-mode\")\n\tcontains(command, \"--config\")\n\n\tnot obj.data.configFile.content\n\n\tmsga := {\n\t\t\"alertMessage\": \"Failed to analyze config file\",\n\t\t\"alertScore\": 6,\n\t\t\"reviewPaths\": [],\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": obj.data\n\t\t}}\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Do not allow all requests. Enable explicit authorization.",
          "remediation": "Change authorization mode to Webhook.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 6
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-3.2.3 Ensure that the --client-ca-file argument is set as appropriate",
      "controlID": "C-0174",
      "creationTime": "",
      "description": "Enable Kubelet authentication using certificates.",
      "remediation": "**Remediation Method 1:**\n\n If modifying the Kubelet config file, edit the kubelet-config.json file `/etc/kubernetes/kubelet/kubelet-config.json` and set the below parameter to false\n\n \n```\n\"authentication\": { \"x509\": {\"clientCAFile:\" to the location of the client CA file.\n\n```\n **Remediation Method 2:**\n\n If using executable arguments, edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` on each worker node and add the below parameter at the end of the `KUBELET_ARGS` variable string.\n\n \n```\n--client-ca-file=<path/to/client-ca-file>\n\n```\n **Remediation Method 3:**\n\n If using the api configz endpoint consider searching for the status of `\"authentication.*x509\":(\"clientCAFile\":\"/etc/kubernetes/pki/ca.crt\"` by extracting the live configuration from the nodes running kubelet.\n\n \\*\\*See detailed step-by-step configmap procedures in [Reconfigure a Node's Kubelet in a Live Cluster](https://kubernetes.io/docs/tasks/administer-cluster/reconfigure-kubelet/), and then rerun the curl statement from audit process to check for kubelet configuration changes\n\n \n```\nkubectl proxy --port=8001 &\n\nexport HOSTNAME_PORT=localhost:8001 (example host and port number)\nexport NODE_NAME=ip-192.168.31.226.aks.internal (example node name from \"kubectl get nodes\")\n\ncurl -sSL \"http://${HOSTNAME_PORT}/api/v1/nodes/${NODE_NAME}/proxy/configz\"\n\n```\n **For all three remediations:**\nBased on your system, restart the `kubelet` service and check status\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\nsystemctl status kubelet -l\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "enforce-kubelet-client-tls-authentication-updated",
          "attributes": {
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n# CIS 4.2.3 https://workbench.cisecurity.org/sections/1126668/recommendations/1838643\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--client-ca-file\")\n\tcontains(command, \"--config\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\tnot yamlConfig.authentication.x509.clientCAFile\n\n\tmsga := {\n\t\t\"alertMessage\": \"kubelet client TLS authentication is not enabled\",\n\t\t\"alertScore\": 6,\n\t\t\"reviewPaths\": [\"authentication.x509.clientCAFile\"],\n\t\t\"failedPaths\": [\"authentication.x509.clientCAFile\"],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}},\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--client-ca-file\")\n\tnot contains(command, \"--config\")\n\n\tmsga := {\n\t\t\"alertMessage\": \"kubelet client TLS authentication is not enabled\",\n\t\t\"alertScore\": 6,\n\t\t\"reviewPaths\": [],\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": {\"cmdLine\": command},\n\t\t}},\n\t}\n}\n\n## Host sensor failed to get config file content\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--client-ca-file\")\n\tcontains(command, \"--config\")\n\n\tnot obj.data.configFile.content\n\n\tmsga := {\n\t\t\"alertMessage\": \"Failed to analyze config file\",\n\t\t\"alertScore\": 6,\n\t\t\"reviewPaths\": [],\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": obj.data,\n\t\t}},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Determines if kubelet client tls authentication is enabled.",
          "remediation": "Start the kubelet with the --client-ca-file flag, providing a CA bundle to verify client certificates with.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 6
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-3.2.4 Ensure that the --read-only-port is secured",
      "controlID": "C-0175",
      "creationTime": "",
      "description": "Disable the read-only port.",
      "remediation": "If modifying the Kubelet config file, edit the kubelet-config.json file `/etc/kubernetes/kubelet/kubelet-config.json` and set the below parameter to false\n\n \n```\nreadOnlyPort to 0\n\n```\n If using executable arguments, edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` on each worker node and add the below parameter at the end of the `KUBELET_ARGS` variable string.\n\n \n```\n--read-only-port=0\n\n```\n For all remediations:\nBased on your system, restart the `kubelet` service and check status\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\nsystemctl status kubelet -l\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "read-only-port-enabled-updated",
          "attributes": {
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# CIS 4.2.4 https://workbench.cisecurity.org/sections/1126668/recommendations/1838645\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tcontains(command, \"--read-only-port\")\n\tnot contains(command, \"--read-only-port=0\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"kubelet read-only port is not disabled\",\n\t\t\"alertScore\": 4,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": external_obj,\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(obj, \"--read-only-port\")\n\tcontains(command, \"--config\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\n\tyamlConfig.readOnlyPort\n\tnot yamlConfig.readOnlyPort == 0\n\n\tmsga := {\n\t\t\"alertMessage\": \"kubelet read-only port is not disabled\",\n\t\t\"alertScore\": 4,\n\t\t\"reviewPaths\": [\"readOnlyPort\"],\n\t\t\"failedPaths\": [\"readOnlyPort\"],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}},\n\t}\n}\n\n## Host sensor failed to get config file content\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(obj, \"--read-only-port\")\n\tcontains(command, \"--config\")\n\n\tnot obj.data.configFile.content\n\n\tmsga := {\n\t\t\"alertMessage\": \"Failed to analyze config file\",\n\t\t\"alertScore\": 4,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": obj.data,\n\t\t}},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Determines if kubelet has read-only port enabled.",
          "remediation": "Start the kubelet with the --read-only-port flag set to 0.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 4
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-3.2.5 Ensure that the --streaming-connection-idle-timeout argument is not set to 0",
      "controlID": "C-0176",
      "creationTime": "",
      "description": "Do not disable timeouts on streaming connections.",
      "remediation": "**Remediation Method 1:**\n\n If modifying the Kubelet config file, edit the kubelet-config.json file `/etc/kubernetes/kubelet/kubelet-config.json` and set the below parameter to a non-zero value in the format of #h#m#s\n\n \n```\n\"streamingConnectionIdleTimeout\": \"4h0m0s\"\n\n```\n You should ensure that the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` does not specify a `--streaming-connection-idle-timeout` argument because it would override the Kubelet config file.\n\n **Remediation Method 2:**\n\n If using executable arguments, edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` on each worker node and add the below parameter at the end of the `KUBELET_ARGS` variable string.\n\n \n```\n--streaming-connection-idle-timeout=4h0m0s\n\n```\n **Remediation Method 3:**\n\n If using the api configz endpoint consider searching for the status of `\"streamingConnectionIdleTimeout\":` by extracting the live configuration from the nodes running kubelet.\n\n \\*\\*See detailed step-by-step configmap procedures in [Reconfigure a Node's Kubelet in a Live Cluster](https://kubernetes.io/docs/tasks/administer-cluster/reconfigure-kubelet/), and then rerun the curl statement from audit process to check for kubelet configuration changes\n\n \n```\nkubectl proxy --port=8001 &\n\nexport HOSTNAME_PORT=localhost:8001 (example host and port number)\nexport NODE_NAME=ip-192.168.31.226.aks.internal (example node name from \"kubectl get nodes\")\n\ncurl -sSL \"http://${HOSTNAME_PORT}/api/v1/nodes/${NODE_NAME}/proxy/configz\"\n\n```\n **For all three remediations:**\nBased on your system, restart the `kubelet` service and check status\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\nsystemctl status kubelet -l\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "kubelet-streaming-connection-idle-timeout",
          "attributes": {
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# CIS 4.2.5 https://workbench.cisecurity.org/sections/1126668/recommendations/1838646\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tcontains(command, \"--streaming-connection-idle-timeout\")\n\tcontains(command, \"--streaming-connection-idle-timeout=0\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Timeouts on streaming connections are enabled\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": [],\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": external_obj\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--streaming-connection-idle-timeout\")\n\tcontains(command, \"--config\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\tyamlConfig.streamingConnectionIdleTimeout == 0\n\n\tmsga := {\n\t\t\"alertMessage\": \"Timeouts on streaming connections are enabled\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": [\"streamingConnectionIdleTimeout\"],\n\t\t\"failedPaths\": [\"streamingConnectionIdleTimeout\"],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}}\n\t}\n}\n\n## Host sensor failed to get config file content\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--streaming-connection-idle-timeout\")\n\tcontains(command, \"--config\")\n\n\tnot obj.data.configFile.content\n\n\tmsga := {\n\t\t\"alertMessage\": \"Failed to analyze config file\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": [],\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": obj.data\n\t\t}}\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Determines if a kubelet has not disabled timeouts on streaming connections",
          "remediation": "Change value of a --streaming-connection-idle-timeout argument or if using a Kubelet config file, edit the file to set streamingConnectionIdleTimeout to a value other than 0.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 3
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-3.2.6 Ensure that the --protect-kernel-defaults argument is set to true",
      "controlID": "C-0177",
      "creationTime": "",
      "description": "Protect tuned kernel parameters from overriding kubelet default kernel parameter values.",
      "remediation": "**Remediation Method 1:**\n\n If modifying the Kubelet config file, edit the kubelet-config.json file `/etc/kubernetes/kubelet/kubelet-config.json` and set the below parameter to true\n\n \n```\n\"protectKernelDefaults\": \n\n```\n **Remediation Method 2:**\n\n If using executable arguments, edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` on each worker node and add the below parameter at the end of the `KUBELET_ARGS` variable string.\n\n \n```\n----protect-kernel-defaults=true\n\n```\n **Remediation Method 3:**\n\n If using the api configz endpoint consider searching for the status of `\"protectKernelDefaults\":` by extracting the live configuration from the nodes running kubelet.\n\n \\*\\*See detailed step-by-step configmap procedures in [Reconfigure a Node's Kubelet in a Live Cluster](https://kubernetes.io/docs/tasks/administer-cluster/reconfigure-kubelet/), and then rerun the curl statement from audit process to check for kubelet configuration changes\n\n \n```\nkubectl proxy --port=8001 &\n\nexport HOSTNAME_PORT=localhost:8001 (example host and port number)\nexport NODE_NAME=ip-192.168.31.226.aks.internal (example node name from \"kubectl get nodes\")\n\ncurl -sSL \"http://${HOSTNAME_PORT}/api/v1/nodes/${NODE_NAME}/proxy/configz\"\n\n```\n **For all three remediations:**\nBased on your system, restart the `kubelet` service and check status\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\nsystemctl status kubelet -l\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "kubelet-protect-kernel-defaults",
          "attributes": {
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# CIS 4.2.6 https://workbench.cisecurity.org/sections/1126668/recommendations/1838648\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tcontains(command, \"--protect-kernel-defaults\")\n\tnot contains(command, \"--protect-kernel-defaults=true\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Argument --protect-kernel-defaults is not set to true.\",\n\t\t\"alertScore\": 2,\n\t\t\"reviewPaths\": [],\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--protect-kernel-defaults\")\n\tcontains(command, \"--config\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\tnot yamlConfig.protectKernelDefaults == true\n\n\tmsga := {\n\t\t\"alertMessage\": \"Property protectKernelDefaults is not set to true\",\n\t\t\"alertScore\": 2,\n\t\t\"reviewPaths\": [\"protectKernelDefaults\"],\n\t\t\"failedPaths\": [\"protectKernelDefaults\"],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}},\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--protect-kernel-defaults\")\n\tnot contains(command, \"--config\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Argument --protect-kernel-defaults is not set to true.\",\n\t\t\"alertScore\": 2,\n\t\t\"reviewPaths\": [],\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\n## Host sensor failed to get config file content\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--protect-kernel-defaults\")\n\tcontains(command, \"--config\")\n\n\tnot obj.data.configFile.content\n\n\tmsga := {\n\t\t\"alertMessage\": \"Failed to analyze config file\",\n\t\t\"alertScore\": 2,\n\t\t\"reviewPaths\": [],\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": obj.data,\n\t\t}},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Determines if the --protect-kernel-defaults argument is set to true.",
          "remediation": "Set --protect-kernel-defaults to true or if using a config file set the protectKernelDefaults as true",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 2
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-3.2.7 Ensure that the --make-iptables-util-chains argument is set to true",
      "controlID": "C-0178",
      "creationTime": "",
      "description": "Allow Kubelet to manage iptables.",
      "remediation": "**Remediation Method 1:**\n\n If modifying the Kubelet config file, edit the kubelet-config.json file `/etc/kubernetes/kubelet/kubelet-config.json` and set the below parameter to false\n\n \n```\n\"makeIPTablesUtilChains\": true\n\n```\n **Remediation Method 2:**\n\n If using executable arguments, edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` on each worker node and add the below parameter at the end of the `KUBELET_ARGS` variable string.\n\n \n```\n--make-iptables-util-chains:true\n\n```\n **Remediation Method 3:**\n\n If using the api configz endpoint consider searching for the status of `\"makeIPTablesUtilChains\": true` by extracting the live configuration from the nodes running kubelet.\n\n \\*\\*See detailed step-by-step configmap procedures in [Reconfigure a Node's Kubelet in a Live Cluster](https://kubernetes.io/docs/tasks/administer-cluster/reconfigure-kubelet/), and then rerun the curl statement from audit process to check for kubelet configuration changes\n\n \n```\nkubectl proxy --port=8001 &\n\nexport HOSTNAME_PORT=localhost:8001 (example host and port number)\nexport NODE_NAME=ip-192.168.31.226.aks.internal (example node name from \"kubectl get nodes\")\n\ncurl -sSL \"http://${HOSTNAME_PORT}/api/v1/nodes/${NODE_NAME}/proxy/configz\"\n\n```\n **For all three remediations:**\nBased on your system, restart the `kubelet` service and check status\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\nsystemctl status kubelet -l\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "kubelet-ip-tables",
          "attributes": {
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# CIS 4.2.7 https://workbench.cisecurity.org/sections/1126668/recommendations/1838651\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tcontains(command, \"--make-iptables-util-chains\")\n\tnot contains(command, \"--make-iptables-util-chains=true\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Argument --make-iptables-util-chains is not set to true.\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": [],\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--make-iptables-util-chains\")\n\tcontains(command, \"--config\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\tnot yamlConfig.makeIPTablesUtilChains == true\n\n\tmsga := {\n\t\t\"alertMessage\": \"Property makeIPTablesUtilChains is not set to true\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": [\"makeIPTablesUtilChains\"],\n\t\t\"failedPaths\": [\"makeIPTablesUtilChains\"],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}},\n\t}\n}\n\n## Host sensor failed to get config file content\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--make-iptables-util-chains\")\n\tcontains(command, \"--config\")\n\n\tnot obj.data.configFile.content\n\n\tmsga := {\n\t\t\"alertMessage\": \"Failed to analyze config file\",\n\t\t\"alertScore\": 6,\n\t\t\"reviewPaths\": [],\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": obj.data,\n\t\t}},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensures that the --make-iptables-util-chains argument is set to true.",
          "remediation": "Set --make-iptables-util-chains to true or if using a config file set the makeIPTablesUtilChains as true",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 3
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-3.2.8 Ensure that the --hostname-override argument is not set",
      "controlID": "C-0179",
      "creationTime": "",
      "description": "Do not override node hostnames.",
      "remediation": "**Remediation Method 1:**\n\n If using executable arguments, edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` on each worker node and remove the below parameter from the `KUBELET_ARGS` variable string.\n\n \n```\n--hostname-override\n\n```\n Based on your system, restart the `kubelet` service and check status. The example below is for systemctl:\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\nsystemctl status kubelet -l\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "kubelet-hostname-override",
          "attributes": {
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# CIS 4.2.8 https://workbench.cisecurity.org/sections/1126668/recommendations/1838654\n\ndeny[msga] {\n\tkubelet_info := input[_]\n\tkubelet_info.kind == \"KubeletInfo\"\n\tkubelet_info.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tcommand := kubelet_info.data.cmdLine\n\n\tcontains(command, \"--hostname-override\")\n\n\texternal_obj := json.filter(kubelet_info, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Argument --hostname-override is set.\",\n\t\t\"alertScore\": 3,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the --hostname-override argument is not set.",
          "remediation": "Unset the --hostname-override argument.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 3
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-3.2.9 Ensure that the --eventRecordQPS argument is set to 0 or a level which ensures appropriate event capture",
      "controlID": "C-0180",
      "creationTime": "",
      "description": "Security relevant information should be captured. The `--eventRecordQPS` flag on the Kubelet can be used to limit the rate at which events are gathered. Setting this too low could result in relevant events not being logged, however the unlimited setting of `0` could result in a denial of service on the kubelet.",
      "remediation": "**Remediation Method 1:**\n\n If modifying the Kubelet config file, edit the kubelet-config.json file `/etc/kubernetes/kubelet/kubelet-config.json` and set the below parameter to 5 or a value greater or equal to 0\n\n \n```\n\"eventRecordQPS\": 5\n\n```\n Check that `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` does not define an executable argument for `eventRecordQPS` because this would override your Kubelet config.\n\n **Remediation Method 2:**\n\n If using executable arguments, edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` on each worker node and add the below parameter at the end of the `KUBELET_ARGS` variable string.\n\n \n```\n--eventRecordQPS=5\n\n```\n **Remediation Method 3:**\n\n If using the api configz endpoint consider searching for the status of `\"eventRecordQPS\"` by extracting the live configuration from the nodes running kubelet.\n\n \\*\\*See detailed step-by-step configmap procedures in [Reconfigure a Node's Kubelet in a Live Cluster](https://kubernetes.io/docs/tasks/administer-cluster/reconfigure-kubelet/), and then rerun the curl statement from audit process to check for kubelet configuration changes\n\n \n```\nkubectl proxy --port=8001 &\n\nexport HOSTNAME_PORT=localhost:8001 (example host and port number)\nexport NODE_NAME=ip-192.168.31.226.aks.internal (example node name from \"kubectl get nodes\")\n\ncurl -sSL \"http://${HOSTNAME_PORT}/api/v1/nodes/${NODE_NAME}/proxy/configz\"\n\n```\n **For all three remediations:**\nBased on your system, restart the `kubelet` service and check status\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\nsystemctl status kubelet -l\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "kubelet-event-qps",
          "attributes": {
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# CIS 4.2.9 https://workbench.cisecurity.org/sections/1126668/recommendations/1838656\n\n# if --event-qps is present rule should pass\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\t# \"--event-qps\" is DEPRECATED\n\t# not contains(command, \"--event-qps\")\n\tcontains(command, \"--config\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\tyamlConfig.eventRecordQPS == 0\n\n\tmsga := {\n\t\t\"alertMessage\": \"Value of the eventRecordQPS argument is set to 0\",\n\t\t\"alertScore\": 2,\n\t\t\"reviewPaths\": [\"eventRecordQPS\"],\n\t\t\"failedPaths\": [\"eventRecordQPS\"],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}},\n\t}\n}\n\n## Host sensor failed to get config file content\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\t# \"--event-qps\" is DEPRECATED\n\t# not contains(command, \"--event-qps\")\n\tcontains(command, \"--config\")\n\n\tnot obj.data.configFile.content\n\n\tmsga := {\n\t\t\"alertMessage\": \"Failed to analyze config file\",\n\t\t\"alertScore\": 2,\n\t\t\"reviewPaths\": [],\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": obj.data,\n\t\t}},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the --event-qps argument is set to 0 or a level which ensures appropriate event capture.",
          "remediation": "Set --event-qps argument to appropiate level or if using a config file set the eventRecordQPS property to the value other than 0",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 2
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-3.2.10 Ensure that the --rotate-certificates argument is not set to false",
      "controlID": "C-0182",
      "creationTime": "",
      "description": "Enable kubelet client certificate rotation.",
      "remediation": "**Remediation Method 1:**\n\n If modifying the Kubelet config file, edit the kubelet-config.json file `/etc/kubernetes/kubelet/kubelet-config.json` and set the below parameter to true\n\n \n```\n\"RotateCertificate\":true\n\n```\n Additionally, ensure that the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubelet-args.conf does not set the --RotateCertificate executable argument to false because this would override the Kubelet config file.\n\n **Remediation Method 2:**\n\n If using executable arguments, edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` on each worker node and add the below parameter at the end of the `KUBELET_ARGS` variable string.\n\n \n```\n--RotateCertificate=true\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "kubelet-rotate-certificates",
          "attributes": {
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# CIS 4.2.11 https://workbench.cisecurity.org/sections/1126668/recommendations/1838658\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tcontains(command, \"--rotate-certificates\")\n\tnot contains(command, \"--rotate-certificates=true\")\n\n\texternal_obj := json.filter(obj, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"Kubelet client certificates rotation is disabled\",\n\t\t\"alertScore\": 6,\n\t\t\"reviewPaths\": [],\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--rotate-certificates\")\n\tcontains(command, \"--config\")\n\n\tdecodedConfigContent := base64.decode(obj.data.configFile.content)\n\tyamlConfig := yaml.unmarshal(decodedConfigContent)\n\tyamlConfig.rotateCertificates == false\n\n\tmsga := {\n\t\t\"alertMessage\": \"Kubelet client certificates rotation is disabled\",\n\t\t\"alertScore\": 6,\n\t\t\"reviewPaths\": [\"rotateCertificates\"],\n\t\t\"failedPaths\": [\"rotateCertificates\"],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"metadata\": obj.metadata,\n\t\t\t\"data\": {\"configFile\": {\"content\": decodedConfigContent}},\n\t\t}},\n\t}\n}\n\n## Host sensor failed to get config file content\ndeny[msga] {\n\tobj := input[_]\n\tis_kubelet_info(obj)\n\n\tcommand := obj.data.cmdLine\n\n\tnot contains(command, \"--rotate-certificates\")\n\tcontains(command, \"--config\")\n\n\tnot obj.data.configFile.content\n\n\tmsga := {\n\t\t\"alertMessage\": \"Failed to analyze config file\",\n\t\t\"alertScore\": 6,\n\t\t\"reviewPaths\": [],\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": {\n\t\t\t\"apiVersion\": obj.apiVersion,\n\t\t\t\"kind\": obj.kind,\n\t\t\t\"data\": obj.data,\n\t\t}},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.kind == \"KubeletInfo\"\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the --rotate-certificates argument is not set to false.",
          "remediation": "Verify that the --rotate-certificates argument is not present, or is set to true. If the --rotate-certificates argument is not present, verify that if there is a Kubelet config file specified by --config, that file does not contain rotateCertificates: false.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 6
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-3.2.11 Ensure that the RotateKubeletServerCertificate argument is set to true",
      "controlID": "C-0183",
      "creationTime": "",
      "description": "Enable kubelet server certificate rotation.",
      "remediation": "**Remediation Method 1:**\n\n If modifying the Kubelet config file, edit the kubelet-config.json file `/etc/kubernetes/kubelet/kubelet-config.json` and set the below parameter to true\n\n \n```\n\"RotateKubeletServerCertificate\":true\n\n```\n **Remediation Method 2:**\n\n If using a Kubelet config file, edit the file to set `RotateKubeletServerCertificate to true`.\n\n If using executable arguments, edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` on each worker node and add the below parameter at the end of the `KUBELET_ARGS` variable string.\n\n \n```\n--rotate-kubelet-server-certificate=true\n\n```\n **Remediation Method 3:**\n\n If using the api configz endpoint consider searching for the status of `\"RotateKubeletServerCertificate\":` by extracting the live configuration from the nodes running kubelet.\n\n \\*\\*See detailed step-by-step configmap procedures in [Reconfigure a Node's Kubelet in a Live Cluster](https://kubernetes.io/docs/tasks/administer-cluster/reconfigure-kubelet/), and then rerun the curl statement from audit process to check for kubelet configuration changes\n\n \n```\nkubectl proxy --port=8001 &\n\nexport HOSTNAME_PORT=localhost:8001 (example host and port number)\nexport NODE_NAME=ip-192.168.31.226.aks.internal (example node name from \"kubectl get nodes\")\n\ncurl -sSL \"http://${HOSTNAME_PORT}/api/v1/nodes/${NODE_NAME}/proxy/configz\"\n\n```\n **For all three remediations:**\nBased on your system, restart the `kubelet` service and check status\n\n \n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\nsystemctl status kubelet -l\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "kubelet-rotate-kubelet-server-certificate",
          "attributes": {
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msga] {\n\tkubelet_info := input[_]\n\tkubelet_info.kind == \"KubeletInfo\"\n\tkubelet_info.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\n\tnot should_skip_check(kubelet_info)\n\n\tcommand := kubelet_info.data.cmdLine\n\n\tnot is_RotateKubeletServerCertificate_enabled_via_cli(command)\n\n\texternal_obj := json.filter(kubelet_info, [\"apiVersion\", \"data/cmdLine\", \"kind\", \"metadata\"])\n\n\tmsga := {\n\t\t\"alertMessage\": \"RotateKubeletServerCertificate is not set to true\",\n\t\t\"alertScore\": 6,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": external_obj},\n\t}\n}\n\n## Inner rules\nshould_skip_check(kubelet_info) {\n\tcommand := kubelet_info.data.cmdLine\n\tcontains(command, \"--rotate-server-certificates\")\n}\n\nshould_skip_check(kubelet_info) {\n\tyamlConfigContent := yaml.unmarshal(base64.decode(kubelet_info.data.configFile.content))\n\tyamlConfigContent.serverTLSBootstrap == true\n}\n\nis_RotateKubeletServerCertificate_enabled_via_cli(command) {\n\tcontains(command, \"--feature-gates=\")\n\targs := regex.split(` +`, command)\n\tsome i\n\tregex.match(`RotateKubeletServerCertificate=true`, args[i])\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Verify that the RotateKubeletServerCertificate argument is set to true.",
          "remediation": "Verify that the --rotate-certificates argument is not present, or is set to true. If the --rotate-certificates argument is not present, verify that if there is a Kubelet config file specified by --config, that file does not contain rotateCertificates: false.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 6
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-4.1.1 Ensure that the cluster-admin role is only used where required",
      "controlID": "C-0185",
      "creationTime": "",
      "description": "The RBAC role `cluster-admin` provides wide-ranging powers over the environment and should be used only where and when needed.",
      "remediation": "Identify all clusterrolebindings to the cluster-admin role. Check if they are used and if they need this role or if they could use a role with fewer privileges.\n\n Where possible, first bind users to a lower privileged role and then remove the clusterrolebinding to the cluster-admin role :\n\n \n```\nkubectl delete clusterrolebinding [name]\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "cluster-admin-role",
          "attributes": {
            "resourcesAggregator": "subject-role-rolebinding",
            "useFromKubescapeVersion": "v1.0.133"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# returns subjects with cluster admin role\n# regal ignore:rule-length\ndeny[msga] {\n\tsubjectVector := input[_]\n\n\trole := subjectVector.relatedObjects[i]\n\tendswith(role.kind, \"Role\")\n\n\trolebinding := subjectVector.relatedObjects[j]\n\tendswith(rolebinding.kind, \"Binding\")\n\n\trule := role.rules[p]\n\tsubject := rolebinding.subjects[k]\n\tis_same_subjects(subjectVector, subject)\n\n\t# check only cluster-admin role and only clusterrolebinding\n\trole.metadata.name == \"cluster-admin\"\n\trolebinding.kind == \"ClusterRoleBinding\"\n\n\trule_path := sprintf(\"relatedObjects[%d].rules[%d]\", [i, p])\n\n\tverbs := [\"*\"]\n\tverb_path := [sprintf(\"%s.verbs[%d]\", [rule_path, l]) | verb = rule.verbs[l]; verb in verbs]\n\tcount(verb_path) > 0\n\n\tapi_groups := [\"*\", \"\"]\n\tapi_groups_path := [sprintf(\"%s.apiGroups[%d]\", [rule_path, a]) | apiGroup = rule.apiGroups[a]; apiGroup in api_groups]\n\tcount(api_groups_path) > 0\n\n\tresources := [\"*\"]\n\tresources_path := [sprintf(\"%s.resources[%d]\", [rule_path, l]) | resource = rule.resources[l]; resource in resources]\n\tcount(resources_path) > 0\n\n\tpath := array.concat(resources_path, verb_path)\n\tpath2 := array.concat(path, api_groups_path)\n\tfinalpath := array.concat(path2, [\n\t\tsprintf(\"relatedObjects[%d].subjects[%d]\", [j, k]),\n\t\tsprintf(\"relatedObjects[%d].roleRef.name\", [j]),\n\t])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Subject: %s-%s is bound to cluster-admin role\", [subjectVector.kind, subjectVector.name]),\n\t\t\"alertScore\": 3,\n\t\t\"fixPaths\": [],\n\t\t\"deletePaths\": finalpath,\n\t\t\"failedPaths\": finalpath,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [],\n\t\t\t\"externalObjects\": subjectVector,\n\t\t},\n\t}\n}\n\n# for service accounts\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.namespace == subject.namespace\n}\n\n# for users/ groups\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.apiGroup == subject.apiGroup\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "*"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Role",
                "ClusterRole",
                "ClusterRoleBinding"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "determines which users have cluster admin permissions",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 8
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-4.1.2 Minimize access to secrets",
      "controlID": "C-0186",
      "creationTime": "",
      "description": "The Kubernetes API stores secrets, which may be service account tokens for the Kubernetes API or credentials used by workloads in the cluster. Access to these secrets should be restricted to the smallest possible group of users to reduce the risk of privilege escalation.",
      "remediation": "Where possible, remove `get`, `list` and `watch` access to `secret` objects in the cluster.",
      "rules": [
        {
          "guid": "",
          "name": "rule-can-list-get-secrets-v1",
          "attributes": {
            "useFromKubescapeVersion": "v1.0.133",
            "microsoftK8sThreatMatrix": "Discovery::Access the K8s API server",
            "resourcesAggregator": "subject-role-rolebinding"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# fails if user can list/get secrets \ndeny[msga] {\n\tsubjectVector := input[_]\n\trole := subjectVector.relatedObjects[i]\n\trolebinding := subjectVector.relatedObjects[j]\n\tendswith(role.kind, \"Role\")\n\tendswith(rolebinding.kind, \"Binding\")\n\n\trule := role.rules[p]\n\n\tsubject := rolebinding.subjects[k]\n\tis_same_subjects(subjectVector, subject)\n\nis_same_subjects(subjectVector, subject)\n\trule_path := sprintf(\"relatedObjects[%d].rules[%d]\", [i, p])\n\n\tverbs := [\"get\", \"list\", \"watch\", \"*\"]\n\tverb_path := [sprintf(\"%s.verbs[%d]\", [rule_path, l]) | verb = rule.verbs[l]; verb in verbs]\n\tcount(verb_path) > 0\n\n\tapi_groups := [\"\", \"*\"]\n\tapi_groups_path := [sprintf(\"%s.apiGroups[%d]\", [rule_path, a]) | apiGroup = rule.apiGroups[a]; apiGroup in api_groups]\n\tcount(api_groups_path) > 0\n\n\tresources := [\"secrets\", \"*\"]\n\tresources_path := [sprintf(\"%s.resources[%d]\", [rule_path, l]) | resource = rule.resources[l]; resource in resources]\n\tcount(resources_path) > 0\n\n\tpath := array.concat(resources_path, verb_path)\n\tpath2 := array.concat(path, api_groups_path)\n\tfinalpath := array.concat(path2, [\n\t\tsprintf(\"relatedObjects[%d].subjects[%d]\", [j, k]),\n\t\tsprintf(\"relatedObjects[%d].roleRef.name\", [j]),\n\t])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Subject: %s-%s can read secrets\", [subjectVector.kind, subjectVector.name]),\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": finalpath,\n\t\t\"failedPaths\": finalpath,\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [],\n\t\t\t\"externalObjects\": subjectVector,\n\t\t},\n\t}\n}\n\n# for service accounts\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.namespace == subject.namespace\n}\n\n# for users/ groups\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.apiGroup == subject.apiGroup\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "rbac.authorization.k8s.io"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Role",
                "ClusterRole",
                "ClusterRoleBinding",
                "RoleBinding"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "determines which users can list/get secrets",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 6
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-4.1.3 Minimize wildcard use in Roles and ClusterRoles",
      "controlID": "C-0187",
      "creationTime": "",
      "description": "Kubernetes Roles and ClusterRoles provide access to resources based on sets of objects and actions that can be taken on those objects. It is possible to set either of these to be the wildcard \"\\*\" which matches all items.\n\n Use of wildcards is not optimal from a security perspective as it may allow for inadvertent access to be granted when new resources are added to the Kubernetes API either as CRDs or in later versions of the product.",
      "remediation": "Where possible replace any use of wildcards in clusterroles and roles with specific objects or actions.",
      "rules": [
        {
          "guid": "",
          "name": "rule-list-all-cluster-admins-v1",
          "attributes": {
            "m$K8sThreatMatrix": "Privilege Escalation::Cluster-admin binding",
            "resourcesAggregator": "subject-role-rolebinding",
            "useFromKubescapeVersion": "v1.0.133"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# returns subjects with cluster admin permissions\ndeny[msga] {\n\tsubjectVector := input[_]\n\trole := subjectVector.relatedObjects[i]\n\trolebinding := subjectVector.relatedObjects[j]\n\tendswith(role.kind, \"Role\")\n\tendswith(rolebinding.kind, \"Binding\")\n\n\trule := role.rules[p]\n\tsubject := rolebinding.subjects[k]\n\tis_same_subjects(subjectVector, subject)\n\nis_same_subjects(subjectVector, subject)\n\trule_path := sprintf(\"relatedObjects[%d].rules[%d]\", [i, p])\n\n\tverbs := [\"*\"]\n\tverb_path := [sprintf(\"%s.verbs[%d]\", [rule_path, l]) | verb = rule.verbs[l]; verb in verbs]\n\tcount(verb_path) > 0\n\n\tapi_groups := [\"*\", \"\"]\n\tapi_groups_path := [sprintf(\"%s.apiGroups[%d]\", [rule_path, a]) | apiGroup = rule.apiGroups[a]; apiGroup in api_groups]\n\tcount(api_groups_path) > 0\n\n\tresources := [\"*\"]\n\tresources_path := [sprintf(\"%s.resources[%d]\", [rule_path, l]) | resource = rule.resources[l]; resource in resources]\n\tcount(resources_path) > 0\n\n\tpath := array.concat(resources_path, verb_path)\n\tpath2 := array.concat(path, api_groups_path)\n\tfinalpath := array.concat(path2, [\n\t\tsprintf(\"relatedObjects[%d].subjects[%d]\", [j, k]),\n\t\tsprintf(\"relatedObjects[%d].roleRef.name\", [j]),\n\t])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Subject: %s-%s have high privileges, such as cluster-admin\", [subjectVector.kind, subjectVector.name]),\n\t\t\"alertScore\": 3,\n\t\t\"fixPaths\": [],\n\t\t\"reviewPaths\": finalpath,\n\t\t\"failedPaths\": finalpath,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [],\n\t\t\t\"externalObjects\": subjectVector,\n\t\t},\n\t}\n}\n\n# for service accounts\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.namespace == subject.namespace\n}\n\n# for users/ groups\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.apiGroup == subject.apiGroup\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "rbac.authorization.k8s.io"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Role",
                "ClusterRole",
                "ClusterRoleBinding",
                "RoleBinding"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "determines which users have cluster admin permissions",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 7
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-4.1.4 Minimize access to create pods",
      "controlID": "C-0188",
      "creationTime": "",
      "description": "The ability to create pods in a namespace can provide a number of opportunities for privilege escalation, such as assigning privileged service accounts to these pods or mounting hostPaths with access to sensitive data (unless Pod Security Policies are implemented to restrict this access)\n\n As such, access to create new pods should be restricted to the smallest possible group of users.",
      "remediation": "Where possible, remove `create` access to `pod` objects in the cluster.",
      "rules": [
        {
          "guid": "",
          "name": "rule-can-create-pod",
          "attributes": {
            "resourcesAggregator": "subject-role-rolebinding",
            "useFromKubescapeVersion": "v1.0.133"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# fails if user has create access to pods\ndeny[msga] {\n\tsubjectVector := input[_]\n\trole := subjectVector.relatedObjects[i]\n\trolebinding := subjectVector.relatedObjects[j]\n\tendswith(role.kind, \"Role\")\n\tendswith(rolebinding.kind, \"Binding\")\n\n\trule := role.rules[p]\n\n\tsubject := rolebinding.subjects[k]\n\tis_same_subjects(subjectVector, subject)\n\nis_same_subjects(subjectVector, subject)\n\trule_path := sprintf(\"relatedObjects[%d].rules[%d]\", [i, p])\n\n\tverbs := [\"create\", \"*\"]\n\tverb_path := [sprintf(\"%s.verbs[%d]\", [rule_path, l]) | verb = rule.verbs[l]; verb in verbs]\n\tcount(verb_path) > 0\n\n\tapi_groups := [\"\", \"*\"]\n\tapi_groups_path := [sprintf(\"%s.apiGroups[%d]\", [rule_path, a]) | apiGroup = rule.apiGroups[a]; apiGroup in api_groups]\n\tcount(api_groups_path) > 0\n\n\tresources := [\"pods\", \"*\"]\n\tresources_path := [sprintf(\"%s.resources[%d]\", [rule_path, l]) | resource = rule.resources[l]; resource in resources]\n\tcount(resources_path) > 0\n\n\tpath := array.concat(resources_path, verb_path)\n\tpath2 := array.concat(path, api_groups_path)\n\tfinalpath := array.concat(path2, [\n\t\tsprintf(\"relatedObjects[%d].subjects[%d]\", [j, k]),\n\t\tsprintf(\"relatedObjects[%d].roleRef.name\", [j]),\n\t])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Subject: %s-%s can create pods\", [subjectVector.kind, subjectVector.name]),\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": finalpath,\n\t\t\"failedPaths\": finalpath,\n\t\t\"fixPaths\": [],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [],\n\t\t\t\"externalObjects\": subjectVector,\n\t\t},\n\t}\n}\n\n# for service accounts\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.namespace == subject.namespace\n}\n\n# for users/ groups\nis_same_subjects(subjectVector, subject) {\n\tsubjectVector.kind == subject.kind\n\tsubjectVector.name == subject.name\n\tsubjectVector.apiGroup == subject.apiGroup\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "rbac.authorization.k8s.io"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Role",
                "ClusterRole",
                "ClusterRoleBinding",
                "RoleBinding"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "determines which users can create pods",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 5
    },
    {
      "rulesIDs": [
        "",
        ""
      ],
      "guid": "",
      "name": "CIS-4.1.5 Ensure that default service accounts are not actively used.",
      "controlID": "C-0189",
      "creationTime": "",
      "description": "The `default` service account should not be used to ensure that rights granted to applications can be more easily audited and reviewed.",
      "remediation": "Create explicit service accounts wherever a Kubernetes workload requires specific access to the Kubernetes API server.\n\n Modify the configuration of each default service account to include this value\n\n \n```\nautomountServiceAccountToken: false\n\n```\n Automatic remediation for the default account:\n\n `kubectl patch serviceaccount default -p $'automountServiceAccountToken: false'`",
      "rules": [
        {
          "guid": "",
          "name": "automount-default-service-account",
          "creationTime": "",
          "rule": "package armo_builtins\n\n# Fails if user account mount tokens in pod by default\ndeny [msga]{\n    service_accounts := [service_account |  service_account= input[_]; service_account.kind == \"ServiceAccount\"]\n    service_account := service_accounts[_]\n\tservice_account.metadata.name == \"default\"\n    result := is_auto_mount(service_account)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\n    msga := {\n\t    \"alertMessage\": sprintf(\"the following service account: %v in the following namespace: %v mounts service account tokens in pods by default\", [service_account.metadata.name, service_account.metadata.namespace]),\n\t\t\"alertScore\": 9,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"fixPaths\": fixed_path,\n\t\t\"deletePaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [service_account]\n\t\t}\n\t}\n}    \n\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n\n #  -- ----     For SAs     -- ----     \nis_auto_mount(service_account)  =  [failed_path, fix_path]  {\n\tservice_account.automountServiceAccountToken == true\n\tfailed_path = \"automountServiceAccountToken\"\n\tfix_path = \"\"\n}\n\nis_auto_mount(service_account)=  [failed_path, fix_path]  {\n\tnot service_account.automountServiceAccountToken == false\n\tnot service_account.automountServiceAccountToken == true\n\tfix_path = {\"path\": \"automountServiceAccountToken\", \"value\": \"false\"}\n\tfailed_path = \"\"\n}\n",
          "resourceEnumerator": "package armo_builtins\n\n# Fails if user account mount tokens in pod by default\ndeny [msga]{\n    service_accounts := [service_account |  service_account= input[_]; service_account.kind == \"ServiceAccount\"]\n    service_account := service_accounts[_]\n\tservice_account.metadata.name == \"default\"\n\n    msga := {\n\t    \"alertMessage\": sprintf(\"the following service account: %v in the following namespace: %v mounts service account tokens in pods by default\", [service_account.metadata.name, service_account.metadata.namespace]),\n\t\t\"alertScore\": 9,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [service_account]\n\t\t}\n\t}\n}    \n",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ServiceAccount"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if default service account mounts service account token by default",
          "remediation": "Make sure that the automountServiceAccountToken field on the default service account spec is set to false",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "namespace-without-service-account",
          "creationTime": "",
          "rule": "package armo_builtins\n\n\n# Fails if namespace does not have service accounts (not incluiding default)\ndeny[msga] {\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\tserviceAccounts := [serviceaccount |  serviceaccount= input[_]; is_good_sa(serviceaccount, namespace.metadata.name)]\n\tcount(serviceAccounts) < 1\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not have any service accounts besides 'default'\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\t\n\t\nis_good_sa(sa, namespace) { \n\tsa.kind == \"ServiceAccount\"\n\tsa.metadata.namespace == namespace\n\tsa.metadata.name != \"default\"\n}",
          "resourceEnumerator": "package armo_builtins\n\n\n# Fails if namespace does not have service accounts (not incluiding default)\ndeny[msga] {\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\t\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not have any service accounts besides 'default'\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "*"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Namespace",
                "ServiceAccount"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if namespace does not have service accounts (not incluiding default)",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 5
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-4.1.6 Ensure that Service Account Tokens are only mounted where necessary",
      "controlID": "C-0190",
      "creationTime": "",
      "description": "Service accounts tokens should not be mounted in pods except where the workload running in the pod explicitly needs to communicate with the API server",
      "remediation": "Modify the definition of pods and service accounts which do not need to mount service account tokens to disable it.",
      "rules": [
        {
          "guid": "",
          "name": "automount-service-account",
          "creationTime": "",
          "rule": "package armo_builtins\n\n# Fails if user account mount tokens in pod by default\ndeny [msga]{\n    service_accounts := [service_account |  service_account= input[_]; service_account.kind == \"ServiceAccount\"]\n    service_account := service_accounts[_]\n    result := is_auto_mount(service_account)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\n    msga := {\n\t    \"alertMessage\": sprintf(\"the following service account: %v in the following namespace: %v mounts service account tokens in pods by default\", [service_account.metadata.name, service_account.metadata.namespace]),\n\t\t\"alertScore\": 9,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"fixPaths\": fixed_path,\n\t\t\"deletePaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [service_account]\n\t\t}\n\t}\n}    \n\n\n #  -- ----     For workloads     -- ----   \n# Fails if pod mount tokens  by default (either by its config or by its SA config)\n\n # POD  \ndeny [msga]{\n    pod := input[_]\n\tpod.kind == \"Pod\"\n\n\tstart_of_path := \"spec.\"\n\twl_namespace := pod.metadata.namespace\n\tresult := is_sa_auto_mounted(pod.spec, start_of_path, wl_namespace)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\n    msga := {\n\t    \"alertMessage\": sprintf(\"Pod: %v in the following namespace: %v mounts service account tokens by default\", [pod.metadata.name, pod.metadata.namespace]),\n\t\t\"alertScore\": 9,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"fixPaths\": fixed_path,\n\t\t\"deletePaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}    \n\n# WORKLOADS\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\tstart_of_path := \"spec.template.spec.\"\n\n\twl_namespace := wl.metadata.namespace\n\tresult := is_sa_auto_mounted(wl.spec.template.spec, start_of_path, wl_namespace)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\n\tmsga := {\n\t\t\"alertMessage\":  sprintf(\"%v: %v in the following namespace: %v mounts service account tokens by default\", [wl.kind, wl.metadata.name, wl.metadata.namespace]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"deletePaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# CRONJOB\ndeny[msga] {\n  \twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer = wl.spec.jobTemplate.spec.template.spec.containers[i]\n\tstart_of_path := \"spec.jobTemplate.spec.template.spec.\"\n   \n\twl_namespace := wl.metadata.namespace\n\tresult := is_sa_auto_mounted(wl.spec.jobTemplate.spec.template.spec, start_of_path, wl.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v in the following namespace: %v mounts service account tokens by default\", [wl.kind, wl.metadata.name, wl.metadata.namespace]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"deletePaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n\n #  -- ----     For workloads     -- ----     \nis_sa_auto_mounted(spec, start_of_path, wl_metadata) = [failed_path, fix_path]   {\n\t# automountServiceAccountToken not in pod spec\n\tnot spec.automountServiceAccountToken == false\n\tnot spec.automountServiceAccountToken == true\n\n\t# check if SA  automount by default\n\tsa := input[_]\n\tis_same_sa(spec, sa.metadata.name)\n\tis_same_namespace(sa.metadata , wl_metadata)\n\tnot sa.automountServiceAccountToken == false\n\n\t# path is pod spec\n\tfix_path = { \"path\": sprintf(\"%vautomountServiceAccountToken\", [start_of_path]), \"value\": \"false\"}\n\tfailed_path = \"\"\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\nis_sa_auto_mounted(spec, start_of_path, wl_namespace) =  [failed_path, fix_path]  {\n\t# automountServiceAccountToken set to true in pod spec\n\tspec.automountServiceAccountToken == true\n\t\n\t# SA automount by default\n\tservice_accounts := [service_account | service_account = input[_]; service_account.kind == \"ServiceAccount\"]\n\tcount(service_accounts) > 0\n\tsa := service_accounts[_]\n\tis_same_sa(spec, sa.metadata.name)\n\tis_same_namespace(sa.metadata , wl_namespace)\n\tnot sa.automountServiceAccountToken == false\n\n\tfailed_path = sprintf(\"%vautomountServiceAccountToken\", [start_of_path])\n\tfix_path = \"\"\n}\n\nis_sa_auto_mounted(spec, start_of_path, wl_namespace) =  [failed_path, fix_path]  {\n\t# automountServiceAccountToken set to true in pod spec\n\tspec.automountServiceAccountToken == true\n\t\n\t# No SA (yaml scan)\n\tservice_accounts := [service_account | service_account = input[_]; service_account.kind == \"ServiceAccount\"]\n\tcount(service_accounts) == 0\n\tfailed_path = sprintf(\"%vautomountServiceAccountToken\", [start_of_path])\n\tfix_path = \"\"\n}\n\n\n\n #  -- ----     For SAs     -- ----     \nis_auto_mount(service_account)  =  [failed_path, fix_path]  {\n\tservice_account.automountServiceAccountToken == true\n\tfailed_path = \"automountServiceAccountToken\"\n\tfix_path = \"\"\n}\n\nis_auto_mount(service_account)=  [failed_path, fix_path]  {\n\tnot service_account.automountServiceAccountToken == false\n\tnot service_account.automountServiceAccountToken == true\n\tfix_path = {\"path\": \"automountServiceAccountToken\", \"value\": \"false\"}\n\tfailed_path = \"\"\n}\n\nis_same_sa(spec, serviceAccountName) {\n\tspec.serviceAccountName == serviceAccountName\n}\n\nis_same_sa(spec, serviceAccountName) {\n\tnot spec.serviceAccountName \n\tserviceAccountName == \"default\"\n}\n\n\nis_same_namespace(metadata1, metadata2) {\n\tmetadata1.namespace == metadata2.namespace\n}\n\nis_same_namespace(metadata1, metadata2) {\n\tnot metadata1.namespace\n\tnot metadata2.namespace\n}\n\nis_same_namespace(metadata1, metadata2) {\n\tnot metadata2.namespace\n\tmetadata1.namespace == \"default\"\n}\n\nis_same_namespace(metadata1, metadata2) {\n\tnot metadata1.namespace\n\tmetadata2.namespace == \"default\"\n}",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod",
                "ServiceAccount"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if service account and workloads mount service account token by default",
          "remediation": "Make sure that the automountServiceAccountToken field on the service account spec if set to false",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 5
    },
    {
      "rulesIDs": [
        "",
        ""
      ],
      "guid": "",
      "name": "CIS-4.2.8 Minimize the admission of containers with capabilities assigned",
      "controlID": "C-0201",
      "creationTime": "",
      "description": "Do not generally permit containers with capabilities",
      "remediation": "Review the use of capabilities in applications running on your cluster. Where a namespace contains applications which do not require any Linux capabilities to operate consider adding a PSP which forbids the admission of containers which do not drop all capabilities.",
      "rules": [
        {
          "guid": "",
          "name": "pod-security-admission-restricted-applied-1",
          "creationTime": "",
          "rule": "package armo_builtins\nimport future.keywords.every\n\n# Fails if namespace does not have relevant labels and no 3rd party security admission exists\ndeny[msga] {\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\tnot restricted_admission_policy_enabled(namespace)\n    not has_external_policy_control(input)\n\tfix_path = {\"path\": \"metadata.labels[pod-security.kubernetes.io/enforce]\", \"value\": \"restricted\"}\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable restricted pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [fix_path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot restricted_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\nrestricted_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue ==  \"restricted\"\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "resourceEnumerator": "package armo_builtins\nimport future.keywords.every\n\n# if no 3rd party security admission exists - Fails if namespace does not have relevant labels \ndeny[msga] {\n    not has_external_policy_control(input)\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable restricted pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot restricted_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\nrestricted_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue ==  \"restricted\"\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Namespace"
              ]
            },
            {
              "apiGroups": [
                "admissionregistration.k8s.io"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "MutatingWebhookConfiguration"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Checks that every namespace enabled restricted pod security admission, or if there are external policies applied for namespaced resources (validating/mutating webhooks) - returns them to be reviewed",
          "remediation": "Ensure that either Pod Security Admission or an external policy control system is in place for every namespace which contains user workloads.\n\n#### Impact Statement\nWhere policy control systems are in place, there is a risk that workloads required for the operation of the cluster may be stopped from running. Care is required when implementing admission control policies to ensure that this does not occur.\n\n#### Default Value\nBy default, Pod Security Admission is enabled but no policies are in place.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "pod-security-admission-restricted-applied-2",
          "creationTime": "",
          "rule": "package armo_builtins\nimport future.keywords.every\n\n# Fails if namespace does not have relevant labels and no 3rd party security admission exists\ndeny[msga] {\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\tnot restricted_admission_policy_enabled(namespace)\n    not has_external_policy_control(input)\n\tfix_path = {\"path\": \"metadata.labels[pod-security.kubernetes.io/enforce]\", \"value\": \"restricted\"}\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable restricted pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [fix_path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot restricted_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\nrestricted_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue ==  \"restricted\"\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "resourceEnumerator": "package armo_builtins\nimport future.keywords.every\n\n# if no 3rd party security admission exists - Fails if namespace does not have relevant labels \ndeny[msga] {\n    not has_external_policy_control(input)\n\tnamespace := input[_]\n\tnamespace.kind == \"Namespace\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Namespace: %v does not enable restricted pod security admission\", [namespace.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\n# Fails if at least 1 namespace does not have relevant labels and 3rd party security admission EXISTS\n# returns webhook configuration for user to review\ndeny[msga] {\n\tsome namespace in input\n\tnamespace.kind == \"Namespace\"\n\tnot restricted_admission_policy_enabled(namespace)\n\n    admissionwebhook := input[_]\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Review webhook: %v ensure that it defines the required policy\", [admissionwebhook.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [admissionwebhook]\n\t\t}\n\t}\n}\n\nrestricted_admission_policy_enabled(namespace){\n\tsome key, value in namespace.metadata.labels \n    key == \"pod-security.kubernetes.io/enforce\"\n\tvalue ==  \"restricted\"\n}\n\nhas_external_policy_control(inp){\n    some admissionwebhook in inp\n    admissionwebhook.kind in [\"ValidatingWebhookConfiguration\", \"MutatingWebhookConfiguration\"]\n    admissionwebhook.webhooks[i].rules[j].scope != \"Cluster\"\n}",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Namespace"
              ]
            },
            {
              "apiGroups": [
                "admissionregistration.k8s.io"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "ValidatingWebhookConfiguration"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Checks that every namespace enabled restricted pod security admission, or if there are external policies applied for namespaced resources (validating/mutating webhooks) - returns them to be reviewed",
          "remediation": "Ensure that either Pod Security Admission or an external policy control system is in place for every namespace which contains user workloads.\n\n#### Impact Statement\nWhere policy control systems are in place, there is a risk that workloads required for the operation of the cluster may be stopped from running. Care is required when implementing admission control policies to ensure that this does not occur.\n\n#### Default Value\nBy default, Pod Security Admission is enabled but no policies are in place.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 5
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-4.4.1 Ensure latest CNI version is used",
      "controlID": "C-0205",
      "creationTime": "",
      "description": "There are a variety of CNI plugins available for Kubernetes. If the CNI in use does not support Network Policies it may not be possible to effectively restrict traffic in the cluster.",
      "remediation": "As with RBAC policies, network policies should adhere to the policy of least privileged access. Start by creating a deny all policy that restricts all inbound and outbound traffic from a namespace or create a global policy using Calico.",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-cni-in-use-supports-network-policies",
          "attributes": {
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# Deny CNIs that don't support Network Policies.\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\n    is_CNIInfo(obj)\n\n\tnetwork_policy_not_supported(obj.data.CNINames)\n\n\t# filter out irrelevant host-sensor data\n    obj_filtered := json.filter(obj, [\"apiVersion\", \"kind\", \"metadata\", \"data/CNINames\"])\n\n    msg := {\n\t\t\"alertMessage\": \"CNI doesn't support Network Policies.\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": \"\",\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\n\t}\n}\n\nis_CNIInfo(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"CNIInfo\"\n}\n\n\n# deny if Flannel is running without calico\nnetwork_policy_not_supported(CNIs) {\n\t\"Flannel\" in CNIs\n\tnot \"Calico\" in CNIs\n}\n\n# deny if aws is running without any other CNI\nnetwork_policy_not_supported(CNIs) {\n\t\"aws\" in CNIs\n\tcount(CNIs) < 2\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "CNIInfo"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "There are a variety of CNI plugins available for Kubernetes. If the CNI in use does not support Network Policies it may not be possible to effectively restrict traffic in the cluster.",
          "remediation": "If the CNI plugin in use does not support network policies, consideration should be given to making use of a different plugin, or finding an alternate mechanism for restricting traffic in the Kubernetes cluster.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 4
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-4.4.2 Ensure that all Namespaces have Network Policies defined",
      "controlID": "C-0206",
      "creationTime": "",
      "description": "Use network policies to isolate traffic in your cluster network.",
      "remediation": "Follow the documentation and create `NetworkPolicy` objects as you need them.",
      "rules": [
        {
          "guid": "",
          "name": "internal-networking",
          "attributes": {
            "m$K8sThreatMatrix": "Lateral Movement::Container internal networking, Discovery::Network mapping"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n# input: network policies\n# apiversion: networking.k8s.io/v1\n# fails if no network policies are defined in a certain namespace\n\ndeny[msga] {\n\tnamespaces := [namespace | namespace = input[_]; namespace.kind == \"Namespace\"]\n\tnamespace := namespaces[_]\n\tpolicy_names := [policy.metadata.namespace | policy = input[_]; policy.kind == \"NetworkPolicy\"]\n\tnot list_contains(policy_names, namespace.metadata.name)\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"no policy is defined for namespace %v\", [namespace.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}\n\nlist_contains(list, element) {\n  some i\n  list[i] == element\n}",
          "resourceEnumerator": "package armo_builtins\n\n# input: network policies + namespaces\n# apiversion: networking.k8s.io/v1\n# returns all namespaces\n\ndeny[msga] {\n\tnamespaces := [namespace | namespace = input[_]; namespace.kind == \"Namespace\"]\n\tnamespace := namespaces[_]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"no policy is defined for namespace %v\", [namespace.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Namespace"
              ]
            },
            {
              "apiGroups": [
                "networking.k8s.io"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "NetworkPolicy"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "lists namespaces in which no network policies are defined",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 4
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-4.5.1 Prefer using secrets as files over secrets as environment variables",
      "controlID": "C-0207",
      "creationTime": "",
      "description": "Kubernetes supports mounting secrets as data volumes or as environment variables. Minimize the use of environment variable secrets.",
      "remediation": "If possible, rewrite application code to read secrets from mounted secret files, rather than from environment variables.",
      "rules": [
        {
          "guid": "",
          "name": "rule-secrets-in-env-var",
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n\tpod := input[_]\n\tpod.kind == \"Pod\"\n\n\tcontainer := pod.spec.containers[i]\n\tenv := container.env[j]\n\tenv.valueFrom.secretKeyRef\n\n\tpath := sprintf(\"spec.containers[%v].env[%v].name\", [format_int(i, 10), format_int(j, 10)])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v has secrets in environment variables\", [pod.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"fixPaths\": [],\n\t\t\"deletePaths\": [path],\n\t\t\"failedPaths\": [path],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\ndeny[msga] {\n\twl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\tcontainer := wl.spec.template.spec.containers[i]\n\tenv := container.env[j]\n\tenv.valueFrom.secretKeyRef\n\n\tpath := sprintf(\"spec.template.spec.containers[%v].env[%v].name\", [format_int(i, 10), format_int(j, 10)])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v has secrets in environment variables\", [wl.kind, wl.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"fixPaths\": [],\n\t\t\"deletePaths\": [path],\n\t\t\"failedPaths\": [path],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer := wl.spec.jobTemplate.spec.template.spec.containers[i]\n\tenv := container.env[j]\n\tenv.valueFrom.secretKeyRef\n\n\tpath := sprintf(\"spec.jobTemplate.spec.template.spec.containers[%v].env[%v].name\", [format_int(i, 10), format_int(j, 10)])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Cronjob: %v has secrets in environment variables\", [wl.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"fixPaths\": [],\n\t\t\"deletePaths\": [path],\n\t\t\"failedPaths\": [path],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if Pods have secrets in environment variables",
          "remediation": "If possible, rewrite application code to read secrets from mounted secret files, rather than from environment variables.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 4
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-4.5.2 Consider external secret storage",
      "controlID": "C-0208",
      "creationTime": "",
      "description": "Consider the use of an external secrets storage and management system, instead of using Kubernetes Secrets directly, if you have more complex secret management needs. Ensure the solution requires authentication to access secrets, has auditing of access to and use of secrets, and encrypts secrets. Some solutions also make it easier to rotate secrets.",
      "remediation": "Refer to the secrets management options offered by your cloud provider or a third-party secrets management solution.",
      "rules": [
        {
          "guid": "",
          "name": "external-secret-storage",
          "attributes": {
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.every\n\n# Encryption config is not using a recommended provider for KMS\ndeny[msg] {\n\tobj = input[_]\n\tis_control_plane_info(obj)\n\tconfig_file := obj.data.APIServerInfo.encryptionProviderConfigFile\n\tconfig_file_content = decode_config_file(base64.decode(config_file.content))\n\n\tresources := config_file_content.resources\n\tevery resource in resources{\n\t\tnot has_recommended_provider(resource)\n\t}\n\n\tfix_paths := [\n\t{\"path\": sprintf(\"resources[%d].resources[%d]\", [count(resources), 0]),\t\"value\": \"secrets\"},\n\t{\"path\": sprintf(\"resources[%d].providers[%d].kms\", [count(resources), 0]),\t\"value\": \"YOUR_EXTERNAL_KMS\"},\n\t]\n\n\t# Add name to the failed object so that\n\t# it fit the format of the alert object\n\tfailed_obj := json.patch(config_file_content, [{\n\t\t\"op\": \"add\",\n\t\t\"path\": \"name\",\n\t\t\"value\": \"encryption-provider-config\",\n\t}])\n\n\tmsg := {\n\t\t\"alertMessage\": \"Encryption provider config is not using a recommended provider for KMS\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": failed_obj},\n\t}\n}\n\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n\ndecode_config_file(content) := parsed {\n\tparsed := yaml.unmarshal(content)\n} else := json.unmarshal(content)\n\nhas_recommended_provider(resource) {\n\trecommended_providers := {\"akeyless\", \"azurekmsprovider\", \"aws-encryption-provider\"}\n\tsome provider in resource.providers\n\trecommended_providers[provider.kms.name]\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            }
          ],
          "ruleDependencies": null,
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Consider the use of an external secrets storage and management system, instead of using Kubernetes Secrets directly, if you have more complex secret management needs. Ensure the solution requires authentication to access secrets, has auditing of access to and use of secrets, and encrypts secrets. Some solutions also make it easier to rotate secrets.",
          "remediation": "Refer to the secrets management options offered by your cloud provider or a third-party secrets management solution.",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 5
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-4.7.1 Create administrative boundaries between resources using namespaces",
      "controlID": "C-0209",
      "creationTime": "",
      "description": "Use namespaces to isolate your Kubernetes objects.",
      "remediation": "Follow the documentation and create namespaces for objects in your deployment as you need them.",
      "rules": [
        {
          "guid": "",
          "name": "list-all-namespaces",
          "creationTime": "",
          "rule": "package armo_builtins\n\n# returns all namespace objects in cluster\ndeny[msga] {\n\tnamespace = input[_]\n\tnamespace.kind == \"Namespace\"\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"review the following namespace: %v\", [namespace.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [namespace]\n\t\t}\n\t}\n}",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Namespace"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "lists all namespaces for users to review",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 5
    },
    {
      "rulesIDs": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
      ],
      "guid": "",
      "name": "CIS-4.7.2 Apply Security Context to Your Pods and Containers",
      "attributes": {
        "controlTypeTags": [
          "security",
          "compliance"
        ],
        "attackTracks": [
          {
            "attackTrack": "workload-external-track",
            "categories": [
              "Privilege Escalation (Node)"
            ]
          }
        ]
      },
      "controlID": "C-0211",
      "creationTime": "",
      "description": "Apply Security Context to Your Pods and Containers",
      "remediation": "As a best practice we recommend that you scope the binding for privileged pods to service accounts within a particular namespace, e.g. kube-system, and limiting access to that namespace. For all other serviceaccounts/namespaces, we recommend implementing a more restrictive policy such as this:\n\n \n```\napiVersion: policy/v1beta1\nkind: PodSecurityPolicy\nmetadata:\n    name: restricted\n    annotations:\n    seccomp.security.alpha.kubernetes.io/allowedProfileNames: 'docker/default,runtime/default'\n    apparmor.security.beta.kubernetes.io/allowedProfileNames: 'runtime/default'\n    seccomp.security.alpha.kubernetes.io/defaultProfileName:  'runtime/default'\n    apparmor.security.beta.kubernetes.io/defaultProfileName:  'runtime/default'\nspec:\n    privileged: false\n    # Required to prevent escalations to root.\n    allowPrivilegeEscalation: false\n    # This is redundant with non-root + disallow privilege escalation,\n    # but we can provide it for defense in depth.\n    requiredDropCapabilities:\n    - ALL\n    # Allow core volume types.\n    volumes:\n    - 'configMap'\n    - 'emptyDir'\n    - 'projected'\n    - 'secret'\n    - 'downwardAPI'\n    # Assume that persistentVolumes set up by the cluster admin are safe to use.\n    - 'persistentVolumeClaim'\n    hostNetwork: false\n    hostIPC: false\n    hostPID: false\n    runAsUser:\n    # Require the container to run without root privileges.\n    rule: 'MustRunAsNonRoot'\n    seLinux:\n    # This policy assumes the nodes are using AppArmor rather than SELinux.\n    rule: 'RunAsAny'\n    supplementalGroups:\n    rule: 'MustRunAs'\n    ranges:\n        # Forbid adding the root group.\n        - min: 1\n        max: 65535\n    fsGroup:\n    rule: 'MustRunAs'\n    ranges:\n        # Forbid adding the root group.\n        - min: 1\n        max: 65535\n    readOnlyRootFilesystem: false\n\n```\n This policy prevents pods from running as privileged or escalating privileges. It also restricts the types of volumes that can be mounted and the root supplemental groups that can be added.\n\n Another, albeit similar, approach is to start with policy that locks everything down and incrementally add exceptions for applications that need looser restrictions such as logging agents which need the ability to mount a host path.",
      "rules": [
        {
          "guid": "",
          "name": "rule-privilege-escalation",
          "attributes": {
            "m$K8sThreatMatrix": "Privilege Escalation::privileged container",
            "mitre": "Privilege Escalation",
            "mitreCode": "TA0004"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n# Deny mutating action unless user is in group owning the resource\n\n\n# privileged pods\ndeny[msga] {\n\n\tpod := input[_]\n\tpod.kind == \"Pod\"\n\tcontainer := pod.spec.containers[i]\n\tstart_of_path := \"spec.\"\n\tpath := isPrivilegedContainer(container, i, start_of_path)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"the following pods are defined as privileged: %v\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"fixPaths\": [],\n\t\t\"deletePaths\": path,\n\t\t\"failedPaths\": path,\n         \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n     }\n}\n\n\n# handles majority of workload resources\ndeny[msga] {\n\twl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\tcontainer := wl.spec.template.spec.containers[i]\n\tstart_of_path := \"spec.template.spec.\"\n\tpath := isPrivilegedContainer(container, i, start_of_path)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is defined as privileged:\", [wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"fixPaths\": [],\n\t\t\"deletePaths\": path,\n\t\t\"failedPaths\": path,\n         \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n     }\n}\n\n# handles cronjob\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer := wl.spec.jobTemplate.spec.template.spec.containers[i]\n\tstart_of_path := \"spec.jobTemplate.spec.template.spec.\"\n\tpath := isPrivilegedContainer(container, i, start_of_path)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"the following cronjobs are defined as privileged: %v\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"fixPaths\": [],\n\t\t\"deletePaths\": path,\n\t\t\"failedPaths\": path,\n         \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n     }\n}\n\n\n# Only SYS_ADMIN capabilite\nisPrivilegedContainer(container, i, start_of_path) = path {\n\tnot container.securityContext.privileged == true\n\tpath = [sprintf(\"%vcontainers[%v].securityContext.capabilities.add[%v]\", [start_of_path, format_int(i, 10), format_int(k, 10)]) | capabilite = container.securityContext.capabilities.add[k]; capabilite == \"SYS_ADMIN\"]\n\tcount(path) > 0\n}\n\n# Only securityContext.privileged == true\nisPrivilegedContainer(container, i, start_of_path) = path {\n\tcontainer.securityContext.privileged == true\n\tpath1 = [sprintf(\"%vcontainers[%v].securityContext.capabilities.add[%v]\", [start_of_path, format_int(i, 10), format_int(k, 10)]) | capabilite = container.securityContext.capabilities.add[k]; capabilite == \"SYS_ADMIN\"]\n\tcount(path1) < 1\n\tpath = [sprintf(\"%vcontainers[%v].securityContext.privileged\", [start_of_path, format_int(i, 10)])]\n}\n\n# SYS_ADMIN capabilite && securityContext.privileged == true\nisPrivilegedContainer(container, i, start_of_path) = path {\n\tpath1 = [sprintf(\"%vcontainers[%v].securityContext.capabilities.add[%v]\", [start_of_path, format_int(i, 10), format_int(k, 10)]) | capabilite = container.securityContext.capabilities.add[k]; capabilite == \"SYS_ADMIN\"]\n\tcount(path1) > 0\n\tcontainer.securityContext.privileged == true\n\tpath = array.concat(path1, [sprintf(\"%vcontainers[%v].securityContext.privileged\", [start_of_path, format_int(i, 10)])])\n}",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "determines if pods/deployments defined as privileged true",
          "remediation": "avoid defining pods as privilleged",
          "ruleQuery": "",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "immutable-container-filesystem",
          "creationTime": "",
          "rule": "package armo_builtins\n\n\n# Fails if pods has container with mutable filesystem\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n\tcontainer := pod.spec.containers[i]\n\tstart_of_path := \"spec.\"\n    is_mutable_filesystem(container)\n\tfixPath = {\"path\": sprintf(\"%vcontainers[%d].securityContext.readOnlyRootFilesystem\", [start_of_path, i]), \"value\": \"true\"}\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"container: %v in pod: %v  has  mutable filesystem\", [container.name, pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [fixPath],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n# Fails if workload has  container with mutable filesystem \ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    container := wl.spec.template.spec.containers[i]\n\tstart_of_path := \"spec.template.spec.\"\n    is_mutable_filesystem(container)\n\tfixPath = {\"path\": sprintf(\"%vcontainers[%d].securityContext.readOnlyRootFilesystem\", [start_of_path, i]), \"value\": \"true\"}\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"container :%v in %v: %v has  mutable filesystem\", [container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [fixPath],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n# Fails if cronjob has  container with mutable filesystem \ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer = wl.spec.jobTemplate.spec.template.spec.containers[i]\n\tstart_of_path := \"spec.jobTemplate.spec.template.spec.\"\n\tis_mutable_filesystem(container)\n\tfixPath = {\"path\": sprintf(\"%vcontainers[%d].securityContext.readOnlyRootFilesystem\", [start_of_path, i]), \"value\": \"true\"}\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"container :%v in %v: %v has mutable filesystem\", [container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [fixPath],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Default of readOnlyRootFilesystem is false. This field is only in container spec and not pod spec\nis_mutable_filesystem(container) {\n\tcontainer.securityContext.readOnlyRootFilesystem == false\n}\n\nis_mutable_filesystem(container) {\n\tnot container.securityContext.readOnlyRootFilesystem == false\n    not container.securityContext.readOnlyRootFilesystem == true\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if container has mutable filesystem",
          "remediation": "Make sure that the securityContext.readOnlyRootFilesystem field in the container/pod spec is set to true",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "non-root-containers",
          "creationTime": "",
          "rule": "package armo_builtins\n\n\n################################################################################\n# Rules\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n\tcontainer := pod.spec.containers[i]\n\n\tstart_of_path := \"spec\"\n\talertInfo := evaluate_workload_non_root_container(container, pod, start_of_path)\n\tfixPath := get_fixed_path(alertInfo, i)\n    failed_path := get_failed_path(alertInfo, i) \n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"container: %v in pod: %v  may run as root\", [container.name, pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n        \"fixPaths\": fixPath,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    container := wl.spec.template.spec.containers[i]\n\n\tstart_of_path := \"spec.template.spec\"\n\talertInfo := evaluate_workload_non_root_container(container, wl.spec.template, start_of_path)\n\tfixPath := get_fixed_path(alertInfo, i)\n    failed_path := get_failed_path(alertInfo, i) \n    msga := {\n\t\t\"alertMessage\": sprintf(\"container :%v in %v: %v may run as root\", [container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n        \"fixPaths\": fixPath,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Fails if cronjob has a container configured to run as root\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer = wl.spec.jobTemplate.spec.template.spec.containers[i]\n\n\tstart_of_path := \"spec.jobTemplate.spec.template.spec\"\n\talertInfo := evaluate_workload_non_root_container(container, wl.spec.jobTemplate.spec.template, start_of_path)\n\tfixPath := get_fixed_path(alertInfo, i)\n    failed_path := get_failed_path(alertInfo, i) \n\t\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"container :%v in %v: %v  may run as root\", [container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n        \"fixPaths\": fixPath,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\nget_failed_path(alertInfo, i) = [replace(alertInfo.failed_path,\"container_ndx\",format_int(i,10))] {\n\talertInfo.failed_path != \"\"\n} else = []\n\n\nget_fixed_path(alertInfo, i) = [{\"path\":replace(alertInfo.fixPath[0].path,\"container_ndx\",format_int(i,10)), \"value\":alertInfo.fixPath[0].value}, {\"path\":replace(alertInfo.fixPath[1].path,\"container_ndx\",format_int(i,10)), \"value\":alertInfo.fixPath[1].value}]{\n\tcount(alertInfo.fixPath) == 2\n} else = [{\"path\":replace(alertInfo.fixPath[0].path,\"container_ndx\",format_int(i,10)), \"value\":alertInfo.fixPath[0].value}] {\n\tcount(alertInfo.fixPath) == 1\n}  else = []\n\n#################################################################################\n# Workload evaluation \n\nevaluate_workload_non_root_container(container, pod, start_of_path) = alertInfo {\n\trunAsNonRootValue := get_run_as_non_root_value(container, pod, start_of_path)\n\trunAsNonRootValue.value == false\n\t\n\trunAsUserValue := get_run_as_user_value(container, pod, start_of_path)\n\trunAsUserValue.value == 0\n\n\talertInfo := choose_first_if_defined(runAsUserValue, runAsNonRootValue)\n} else = alertInfo {\n    allowPrivilegeEscalationValue := get_allow_privilege_escalation(container, pod, start_of_path)\n    allowPrivilegeEscalationValue.value == true\n\n    alertInfo := allowPrivilegeEscalationValue\n}\n\n\n#################################################################################\n# Value resolution functions\n# TODO - refactor functions, can be simplified\n\n\nget_run_as_non_root_value(container, pod, start_of_path) = runAsNonRoot {\n    runAsNonRoot := {\"value\" : container.securityContext.runAsNonRoot, \"failed_path\" : \"\", \"fixPath\": [{\"path\": sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [start_of_path]), \"value\":\"true\"}] ,\"defined\" : true}\n} else = runAsNonRoot {\n    runAsNonRoot := {\"value\" : pod.spec.securityContext.runAsNonRoot,  \"failed_path\" : \"\", \"fixPath\": [{\"path\": sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [start_of_path]), \"value\":\"true\"}], \"defined\" : true}\n} else = {\"value\" : false,  \"failed_path\" : \"\", \"fixPath\": [{\"path\": sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [start_of_path]), \"value\":\"true\"}], \"defined\" : false} {\n\tis_allow_privilege_escalation_field(container, pod)\n} else = {\"value\" : false,  \"failed_path\" : \"\", \"fixPath\": [{\"path\":  sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [start_of_path]) , \"value\":\"true\"}, {\"path\":sprintf(\"%v.containers[container_ndx].securityContext.allowPrivilegeEscalation\", [start_of_path]), \"value\":\"false\"}], \"defined\" : false}\n\nget_run_as_user_value(container, pod, start_of_path) = runAsUser {\n\tfailed_path := sprintf(\"%v.containers[container_ndx].securityContext.runAsUser\", [start_of_path]) \n    runAsUser := {\"value\" : container.securityContext.runAsUser,  \"failed_path\" : failed_path,  \"fixPath\": [], \"defined\" : true}\n} else = runAsUser {\n\tfailed_path := sprintf(\"%v.securityContext.runAsUser\", [start_of_path]) \n    runAsUser := {\"value\" : pod.spec.securityContext.runAsUser,  \"failed_path\" : failed_path, \"fixPath\": [],\"defined\" : true}\n} else = {\"value\" : 0, \"failed_path\": \"\", \"fixPath\": [{\"path\":  sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [start_of_path]), \"value\":\"true\"}],\"defined\" : false}{\n\tis_allow_privilege_escalation_field(container, pod)\n} else = {\"value\" : 0, \"failed_path\": \"\", \n\t\"fixPath\": [{\"path\":  sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [start_of_path]), \"value\":\"true\"},{\"path\":  sprintf(\"%v.containers[container_ndx].securityContext.allowPrivilegeEscalation\", [start_of_path]), \"value\":\"false\"}],\n\t\"defined\" : false}\n\nget_run_as_group_value(container, pod, start_of_path) = runAsGroup {\n\tfailed_path := sprintf(\"%v.containers[container_ndx].securityContext.runAsGroup\", [start_of_path])\n    runAsGroup := {\"value\" : container.securityContext.runAsGroup,  \"failed_path\" : failed_path, \"fixPath\": [],\"defined\" : true}\n} else = runAsGroup {\n\tfailed_path := sprintf(\"%v.securityContext.runAsGroup\", [start_of_path])\n    runAsGroup := {\"value\" : pod.spec.securityContext.runAsGroup,  \"failed_path\" : failed_path, \"fixPath\":[], \"defined\" : true}\n} else = {\"value\" : 0, \"failed_path\": \"\", \"fixPath\": [{\"path\": sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [start_of_path]), \"value\":\"true\"}], \"defined\" : false}{\n\tis_allow_privilege_escalation_field(container, pod)\n} else = {\"value\" : 0, \"failed_path\": \"\", \n\t\"fixPath\": [{\"path\": sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [start_of_path]), \"value\":\"true\"},{\"path\": sprintf(\"%v.containers[container_ndx].securityContext.allowPrivilegeEscalation\", [start_of_path]), \"value\":\"false\"}],\n \t\"defined\" : false\n}\n\nget_allow_privilege_escalation(container, pod, start_of_path) = allowPrivilegeEscalation {\n    allowPrivilegeEscalation := {\"value\" : container.securityContext.allowPrivilegeEscalation,  \"failed_path\" : \"\", \"fixPath\": [{\"path\": sprintf(\"%v.containers[container_ndx].securityContext.allowPrivilegeEscalation\", [start_of_path]), \"value\":\"false\"}], \"defined\" : true}\n} else = allowPrivilegeEscalation {\n    allowPrivilegeEscalation := {\"value\" : pod.spec.securityContext.allowPrivilegeEscalation,  \"failed_path\" : \"\", \"fixPath\": [{\"path\": sprintf(\"%v.containers[container_ndx].securityContext.allowPrivilegeEscalation\", [start_of_path]), \"value\":\"false\"}], \"defined\" : true}\n} else = {\"value\" : true, \"failed_path\": \"\", \"fixPath\": [{\"path\": sprintf(\"%v.containers[container_ndx].securityContext.allowPrivilegeEscalation\", [start_of_path]), \"value\":\"false\"}], \"defined\" : false}\n\nchoose_first_if_defined(l1, l2) = c {\n    l1.defined\n    c := l1\n} else = l2\n\n\nis_allow_privilege_escalation_field(container, pod) {\n\tcontainer.securityContext.allowPrivilegeEscalation == false\n}\n\nis_allow_privilege_escalation_field(container, pod) {\n\tpod.spec.securityContext.allowPrivilegeEscalation == false\n}\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if container can run as root",
          "remediation": "Make sure that the user/group in the securityContext of pod/container is set to an id less than 1000, or the runAsNonRoot flag is set to true. Also make sure that the allowPrivilegeEscalation field is set to false",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "drop-capability-netraw",
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# Fails if pod does not drop the capability NET_RAW \ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"Pod\"\n\tpath_to_containers := [\"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n\n\tpath_to_search := [\"securityContext\", \"capabilities\"]\n\tresult := container_doesnt_drop_NET_RAW(container, i, path_to_containers, path_to_search)\n\tfailedPaths := get_failed_path(result)\n    fixPaths := get_fixed_path(result)\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %s does not drop the capability NET_RAW\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"deletePaths\": failedPaths,\n\t\t\"failedPaths\": failedPaths,\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [wl]},\n\t}\n}\n\n# Fails if workload does not drop the capability NET_RAW\ndeny[msga] {\n\twl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\", \"ReplicaSet\", \"DaemonSet\", \"StatefulSet\", \"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\tpath_to_containers := [\"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n\n\tpath_to_search := [\"securityContext\", \"capabilities\"]\n\tresult := container_doesnt_drop_NET_RAW(container, i, path_to_containers, path_to_search)\n\tfailedPaths := get_failed_path(result)\n    fixPaths := get_fixed_path(result)\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v does not drop the capability NET_RAW\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"deletePaths\": failedPaths,\n\t\t\"failedPaths\": failedPaths,\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [wl]},\n\t}\n}\n\n# Fails if CronJob does not drop the capability NET_RAW\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tpath_to_containers := [\"spec\", \"jobTemplate\", \"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n\n\tpath_to_search := [\"securityContext\", \"capabilities\"]\n\tresult := container_doesnt_drop_NET_RAW(container, i, path_to_containers, path_to_search)\n\tfailedPaths := get_failed_path(result)\n    fixPaths := get_fixed_path(result)\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Cronjob: %v does not drop the capability NET_RAW\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"deletePaths\": failedPaths,\n\t\t\"failedPaths\": failedPaths,\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [wl]},\n\t}\n}\n\n# Checks if workload does not drop the capability NET_RAW\ncontainer_doesnt_drop_NET_RAW(container, i, path_to_containers, path_to_search) = [failed_path, fix_path] {\n\tpath_to_drop := array.concat(path_to_search, [\"drop\"])\n\tdrop_list := object.get(container, path_to_drop, [])\n\tnot \"NET_RAW\" in drop_list\n\tnot \"ALL\" in drop_list\n\tnot \"all\" in drop_list\n\tfixpath := sprintf(\"%s[%d].%s[%d]\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_drop), count(drop_list)])\n\tfix_path := [{\"path\": fixpath, \"value\": \"NET_RAW\"}]\n\tfailed_path := \"\"\n}\n\n# Checks if workload drops all capabilities but adds NET_RAW capability\ncontainer_doesnt_drop_NET_RAW(container, i, path_to_containers, path_to_search) = [failed_path, fix_path] {\n\tpath_to_drop := array.concat(path_to_search, [\"drop\"])\n\tdrop_list := object.get(container, path_to_drop, [])\n\tall_in_list(drop_list)\n\tpath_to_add := array.concat(path_to_search, [\"add\"])\n\tadd_list := object.get(container, path_to_add, [])\n\t\"NET_RAW\" in add_list\n\tfailed_path := [sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_add)])]\n\tfix_path := \"\"\n}\n\nall_in_list(list) {\n\t\"all\" in list\n}\n\nall_in_list(list) {\n\t\"ALL\" in list\n}\n\n\nget_failed_path(paths) = paths[0] {\n\tpaths[0] != \"\"\n} else = []\n\n\nget_fixed_path(paths) = paths[1] {\n\tpaths[1] != \"\"\n} else = []\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if container does not drop the capability NET_RAW",
          "remediation": "Define the drop list in security context capabilities to include NET_RAW.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "set-seLinuxOptions",
          "creationTime": "",
          "rule": "package armo_builtins\n\n\n# Fails if pod does not define seLinuxOptions \ndeny[msga] {\n    wl := input[_]\n    wl.kind == \"Pod\"\n    spec := wl.spec\n\tpath_to_search := [\"securityContext\", \"seLinuxOptions\"]\n\tno_seLinuxOptions_in_securityContext(spec, path_to_search)\n\n\tpath_to_containers := [\"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n    no_seLinuxOptions_in_securityContext(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"YOUR_VALUE\"}]\n\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v does not define any seLinuxOptions\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Fails if workload does not define seLinuxOptions\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    spec := wl.spec.template.spec\n\tpath_to_search := [\"securityContext\", \"seLinuxOptions\"]\n\tno_seLinuxOptions_in_securityContext(spec, path_to_search)\n\n\tpath_to_containers := [\"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n    no_seLinuxOptions_in_securityContext(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"YOUR_VALUE\"}]\n\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v does not define any seLinuxOptions\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n# Fails if CronJob does not define seLinuxOptions \ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tspec := wl.spec.jobTemplate.spec.template.spec\n\tpath_to_search := [\"securityContext\", \"seLinuxOptions\"]\n\tno_seLinuxOptions_in_securityContext(spec, path_to_search)\n\n\tpath_to_containers := [\"spec\", \"jobTemplate\", \"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n    no_seLinuxOptions_in_securityContext(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"YOUR_VALUE\"}]\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Cronjob: %v does not define any seLinuxOptions\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\nno_seLinuxOptions_in_securityContext(spec, path_to_search){\n    object.get(spec, path_to_search, \"\") == \"\"\n}",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if workload and container do not define any seLinuxOptions",
          "remediation": "Make sure you set seLinuxOptions in the workload/container security context.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "set-seccomp-profile",
          "creationTime": "",
          "rule": "package armo_builtins\n\n# Fails if pod does not define seccompProfile\ndeny[msga] {\n    wl := input[_]\n    wl.kind == \"Pod\"\n    spec := wl.spec\n\tpath_to_search := [\"securityContext\", \"seccompProfile\"]\n\tseccompProfile_not_defined(spec, path_to_search)\n\n\tpath_to_containers := [\"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n    seccompProfile_not_defined(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"YOUR_VALUE\"}]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v does not define seccompProfile\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Fails if workload does not define seccompProfile\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    spec := wl.spec.template.spec\n\tpath_to_search := [\"securityContext\", \"seccompProfile\"]\n\tseccompProfile_not_defined(spec, path_to_search)\n\n\tpath_to_containers := [\"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n    seccompProfile_not_defined(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"YOUR_VALUE\"}]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v does not define seccompProfile\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n# Fails if CronJob does not define seccompProfile\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n    spec := wl.spec.jobTemplate.spec.template.spec\n\tpath_to_search := [\"securityContext\", \"seccompProfile\"]\n\tseccompProfile_not_defined(spec, path_to_search)\n\n\tpath_to_containers := [\"spec\", \"jobTemplate\", \"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n    seccompProfile_not_defined(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"YOUR_VALUE\"}]\n\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Cronjob: %v does not define seccompProfile\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\nseccompProfile_not_defined(spec, path_to_search){\n\tobject.get(spec, path_to_search, \"\") == \"\"\n}",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "fails if container does not define seccompProfile",
          "remediation": "Make sure you define seccompProfile at workload or container lever.",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "set-procmount-default",
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.if\n\n# Fails if container does not define the \"procMount\" parameter as \"Default\"\ndeny[msga] {\n\t# checks at first if we the procMountType feature gate is enabled on the api-server\n\tobj := input[_]\n\tis_control_plane_info(obj)\n\tis_proc_mount_type_enabled(obj.data.APIServerInfo.cmdLine)\n\n\t# checks if procMount paramenter has the right value in containers\n\tpod := input[_]\n\tpod.kind = \"Pod\"\n\n\t# retrieve container list\n\tcontainer := pod.spec.containers[i]\n\tnot procMountSetProperly(container.securityContext)\n\n\tfixPaths = [{\"path\": sprintf(\"spec.containers[%d].securityContext.procMount\", [i]), \"value\": \"Default\"}]\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v has containers that do not set 'securityContext.procMount' to 'Default'\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [pod]},\n\t}\n}\n\ndeny[msga] {\n\t# checks at first if we the procMountType feature gate is enabled on the api-server\n\tobj := input[_]\n\tis_control_plane_info(obj)\n\tis_proc_mount_type_enabled(obj.data.APIServerInfo.cmdLine)\n\n\t# checks if we are managing the right workload kind\n\twl := input[_]\n\tmanifest_kind := {\"Deployment\", \"ReplicaSet\", \"DaemonSet\", \"StatefulSet\", \"Job\"}\n\tmanifest_kind[wl.kind]\n\n\t# retrieve container list\n\tcontainer := wl.spec.template.spec.containers[i]\n\tnot procMountSetProperly(container.securityContext)\n\n\tfixPaths = [{\"path\": sprintf(\"spec.template.spec.containers[%d].securityContext.procMount\", [i]), \"value\": \"Default\"}]\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v has containers that do not set 'securityContext.procMount' to 'Default'\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [wl]},\n\t}\n}\n\ndeny[msga] {\n\t# checks at first if we the procMountType feature gate is enabled on the api-server\n\tobj := input[_]\n\tis_control_plane_info(obj)\n\tis_proc_mount_type_enabled(obj.data.APIServerInfo.cmdLine)\n\n\t# checks if we are managing the right workload kind\n\tcj := input[_]\n\tcj.kind = \"CronJob\"\n\n\t# retrieve container list\n\tcontainer := cj.spec.jobTemplate.spec.template.spec.containers[i]\n\tnot procMountSetProperly(container.securityContext)\n\n\tfixPaths = [{\"path\": sprintf(\"spec.jobTemplate.spec.template.spec.containers[%d].securityContext.procMount\", [i]), \"value\": \"Default\"}]\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"CronJob: %v has containers that do not set 'securityContext.procMount' to 'Default'\", [cj.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [cj]},\n\t}\n}\n\n# check if we are managing ControlPlaneInfo\nis_control_plane_info(obj) if {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n\n# check if ProcMountType feature-gate is enabled\nis_proc_mount_type_enabled(command) if {\n\tcontains(command, \"--feature-gates=\")\n\targs := regex.split(` +`, command)\n\tsome i\n\tregex.match(`ProcMountType=true`, args[i])\n}\n\n# procMountSetProperly checks if procMount has value of \"Default\".\nprocMountSetProperly(securityContext) if {\n\tsecurityContext.procMount == \"Default\"\n} else := false\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "ControlPlaneInfo"
              ]
            },
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Fails if container does not define securityContext.procMount to Default.",
          "remediation": "Set securityContext.procMount to Default",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "set-fsgroup-value",
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.if\n\n### POD ###\n\n# Fails if securityContext.fsGroup does not have a values >= 0\ndeny[msga] {\n\t# verify the object kind\n\tpod := input[_]\n\tpod.kind = \"Pod\"\n\n\t# check securityContext has fsGroup set properly\n\tnot fsGroupSetProperly(pod.spec.securityContext)\n\n\tsecurityContextPath := \"spec.securityContext\"\n\n\tfixPaths = [{\"path\": sprintf(\"%v.fsGroup\", [securityContextPath]), \"value\": \"YOUR_VALUE\"}]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v does not set 'securityContext.fsGroup' with allowed value\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [pod]},\n\t}\n}\n\n### CRONJOB ###\n\n# Fails if securityContext.fsGroup does not have a values >= 0\ndeny[msga] {\n\t# verify the object kind\n\tcj := input[_]\n\tcj.kind == \"CronJob\"\n\n\t# check securityContext has fsGroup set properly\n\tnot fsGroupSetProperly(cj.spec.jobTemplate.spec.template.spec.securityContext)\n\n\tsecurityContextPath := \"spec.jobTemplate.spec.template.spec.securityContext\"\n\n\tfixPaths = [{\"path\": sprintf(\"%v.fsGroup\", [securityContextPath]), \"value\": \"YOUR_VALUE\"}]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"CronJob: %v does not set 'securityContext.fsGroup' with allowed value\", [cj.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [cj]},\n\t}\n}\n\n### WORKLOAD ###\n\n# Fails if securityContext.fsGroup does not have a values >= 0\ndeny[msga] {\n\t# verify the object kind\n\twl := input[_]\n\tmanifest_kind := {\"Deployment\", \"ReplicaSet\", \"DaemonSet\", \"StatefulSet\", \"Job\"}\n\tmanifest_kind[wl.kind]\n\n\t# check securityContext has fsGroup set properly\n\tnot fsGroupSetProperly(wl.spec.template.spec.securityContext)\n\n\tsecurityContextPath := \"spec.template.spec.securityContext\"\n\tfixPaths = [{\"path\": sprintf(\"%v.fsGroup\", [securityContextPath]), \"value\": \"YOUR_VALUE\"}]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v does not set 'securityContext.fsGroup' with allowed value\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [wl]},\n\t}\n}\n\n# fsGroupSetProperly checks if fsGroup has a value >= 0.\nfsGroupSetProperly(securityContext) if {\n\tsecurityContext.fsGroup >= 0\n} else := false\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Fails if securityContext.fsGroup is not set.",
          "remediation": "Set securityContext.fsGroup value",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "set-fsgroupchangepolicy-value",
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.if\n\n### POD ###\n\n# Fails if securityContext.fsGroupChangePolicy does not have an allowed value\ndeny[msga] {\n    # verify the object kind\n    pod := input[_]\n    pod.kind = \"Pod\"\n    \n    # check securityContext has fsGroupChangePolicy set\n    not fsGroupChangePolicySetProperly(pod.spec.securityContext)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v does not set 'securityContext.fsGroupChangePolicy' with allowed value\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [{\"path\": \"spec.securityContext.fsGroupChangePolicy\", \"value\": \"Always\"}],\n    \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n    }\n}\n\n### WORKLOAD ###\n\n# Fails if securityContext.fsGroupChangePolicy does not have an allowed value\ndeny[msga] {\n    # verify the object kind\n    wl := input[_]\n    manifest_kind := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n    manifest_kind[wl.kind]\n    \n    # check securityContext has fsGroupChangePolicy set\n    not fsGroupChangePolicySetProperly(wl.spec.template.spec.securityContext)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v does not set 'securityContext.fsGroupChangePolicy' with allowed value\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [{\"path\": \"spec.template.spec.securityContext.fsGroupChangePolicy\", \"value\": \"Always\"}],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n    }\n}\n\n### CRONJOB ###\n\n# Fails if securityContext.fsGroupChangePolicy does not have an allowed value\ndeny[msga] {\n    # verify the object kind\n    cj := input[_]\n    cj.kind == \"CronJob\"\n\n    # check securityContext has fsGroupChangePolicy set\n    not fsGroupChangePolicySetProperly(cj.spec.jobTemplate.spec.template.spec.securityContext)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"CronJob: %v does not set 'securityContext.fsGroupChangePolicy' with allowed value\", [cj.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [{\"path\": \"spec.jobTemplate.spec.template.spec.securityContext.fsGroupChangePolicy\", \"value\": \"Always\"}],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [cj]\n\t\t}\n    }\n}\n\n# fsGroupChangePolicySetProperly checks if applied value is set as appropriate [Always|OnRootMismatch]\nfsGroupChangePolicySetProperly(securityContext) := true if {\n    regex.match(securityContext.fsGroupChangePolicy, \"Always|OnRootMismatch\")\n} else := false\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Fails if securityContext.fsGroup is not set.",
          "remediation": "Set securityContext.fsGroup value",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "set-sysctls-params",
          "creationTime": "",
          "rule": "package armo_builtins\n\n### POD ###\n\n# Fails if securityContext.sysctls is not set\ndeny[msga] {\n    # verify the object kind\n\tpod := input[_]\n\tpod.kind = \"Pod\"\n\n\t# check securityContext has sysctls set\n    not pod.spec.securityContext.sysctls\n\n    path := \"spec.securityContext.sysctls\"\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v does not set 'securityContext.sysctls'\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [{\"path\": path, \"name\": \"net.ipv4.tcp_syncookie\", \"value\": \"1\"}],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n    }\n}\n\n### WORKLOAD ###\n\n# Fails if securityContext.sysctls is not set\ndeny[msga] {\n    # verify the object kind\n\twl := input[_]\n\tmanifest_kind := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tmanifest_kind[wl.kind]\n\n\t# check securityContext has sysctls set\n    not wl.spec.template.spec.securityContext.sysctls\n\n    path := \"spec.template.spec.securityContext.sysctls\"\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v does not set 'securityContext.sysctls'\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [{\"path\": path, \"name\": \"net.ipv4.tcp_syncookie\", \"value\": \"1\"}],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n    }\n}\n\n### CRONJOB ###\n\n# Fails if securityContext.sysctls is not set\ndeny[msga] {\n    # verify the object kind\n\tcj := input[_]\n    cj.kind == \"CronJob\"\n\n\t# check securityContext has sysctls set\n    not cj.spec.jobTemplate.spec.template.spec.securityContext.sysctls\n\n    path := \"spec.jobTemplate.spec.template.spec.securityContext.sysctls\"\n    msga := {\n\t\t\"alertMessage\": sprintf(\"CronJob: %v does not set 'securityContext.sysctls'\", [cj.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [{\"path\": path, \"name\": \"net.ipv4.tcp_syncookie\", \"value\": \"1\"}],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [cj]\n\t\t}\n    }\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Fails if securityContext.sysctls is not set.",
          "remediation": "Set securityContext.sysctls params",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "set-supplementalgroups-values",
          "creationTime": "",
          "rule": "package armo_builtins\n\n### POD ###\n\n# Fails if securityContext.supplementalGroups is not set\ndeny[msga] {\n\t# verify the object kind\n\tpod := input[_]\n\tpod.kind = \"Pod\"\n\n\t# check securityContext has supplementalGroups set\n\tnot pod.spec.securityContext.supplementalGroups\n\tfixPaths = [{\"path\": \"spec.securityContext.supplementalGroups\", \"value\": \"YOUR_VALUE\"}]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v does not set 'securityContext.supplementalGroups'\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [pod]},\n\t}\n}\n\n### WORKLOAD ###\n\n# Fails if securityContext.supplementalGroups is not set\ndeny[msga] {\n\t# verify the object kind\n\twl := input[_]\n\tmanifest_kind := {\"Deployment\", \"ReplicaSet\", \"DaemonSet\", \"StatefulSet\", \"Job\"}\n\tmanifest_kind[wl.kind]\n\n\t# check securityContext has supplementalGroups set\n\tnot wl.spec.template.spec.securityContext.supplementalGroups\n\tfixPaths = [{\"path\": \"spec.template.spec.securityContext.supplementalGroups\", \"value\": \"YOUR_VALUE\"}]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v does not set 'securityContext.supplementalGroups'\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [wl]},\n\t}\n}\n\n### CRONJOB ###\n\n# Fails if securityContext.supplementalGroups is not set\ndeny[msga] {\n\t# verify the object kind\n\tcj := input[_]\n\tcj.kind == \"CronJob\"\n\n\t# check securityContext has supplementalGroups set\n\tnot cj.spec.jobTemplate.spec.template.spec.securityContext.supplementalGroups\n\tfixPaths = [{\"path\": \"spec.jobTemplate.spec.template.spec.securityContext.supplementalGroups\", \"value\": \"YOUR_VALUE\"}]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"CronJob: %v does not set 'securityContext.supplementalGroups'\", [cj.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [cj]},\n\t}\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Fails if securityContext.supplementalgroups is not set.",
          "remediation": "Set securityContext.supplementalgroups values",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 8
    },
    {
      "rulesIDs": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
      ],
      "guid": "",
      "name": "CIS-4.7.3 The default namespace should not be used",
      "controlID": "C-0212",
      "creationTime": "",
      "description": "Kubernetes provides a default namespace, where objects are placed if no namespace is specified for them. Placing objects in this namespace makes application of RBAC and other controls more difficult.",
      "remediation": "Ensure that namespaces are created to allow for appropriate segregation of Kubernetes resources and that all new resources are created in a specific namespace.",
      "rules": [
        {
          "guid": "",
          "name": "pods-in-default-namespace",
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\", \"Job\", \"CronJob\", \"Pod\"}\n\tspec_template_spec_patterns[wl.kind]\n\tresult := is_default_namespace(wl.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v has pods running in the 'default' namespace\", [wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tmetadata.namespace == \"default\"\n\tfailed_path = \"metadata.namespace\"\n\tfixPath = \"\" \n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tnot metadata.namespace\n\tfailed_path = \"\"\n\tfixPath = {\"path\": \"metadata.namespace\", \"value\": \"YOUR_NAMESPACE\"} \n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Pod"
              ]
            },
            {
              "apiGroups": [
                "apps"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Deployment",
                "ReplicaSet",
                "DaemonSet",
                "StatefulSet"
              ]
            },
            {
              "apiGroups": [
                "batch"
              ],
              "apiVersions": [
                "*"
              ],
              "resources": [
                "Job",
                "CronJob"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "rolebinding-in-default-namespace",
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n    resource := input[_]\n\tresult := is_default_namespace(resource.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is in the 'default' namespace\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t}\n\t}\n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tmetadata.namespace == \"default\"\n\tfailed_path = \"metadata.namespace\"\n\tfixPath = \"\" \n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tnot metadata.namespace\n\tfailed_path = \"\"\n\tfixPath = {\"path\": \"metadata.namespace\", \"value\": \"YOUR_NAMESPACE\"}\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "rbac.authorization.k8s.io"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "RoleBinding"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "role-in-default-namespace",
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n    resource := input[_]\n\tresult := is_default_namespace(resource.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is in the 'default' namespace\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t}\n\t}\n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tmetadata.namespace == \"default\"\n\tfailed_path = \"metadata.namespace\"\n\tfixPath = \"\" \n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tnot metadata.namespace\n\tfailed_path = \"\"\n\tfixPath = {\"path\": \"metadata.namespace\", \"value\": \"YOUR_NAMESPACE\"}\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "rbac.authorization.k8s.io"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Role"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "configmap-in-default-namespace",
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n    resource := input[_]\n\tresult := is_default_namespace(resource.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is in the 'default' namespace\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t}\n\t}\n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tmetadata.namespace == \"default\"\n\tfailed_path = \"metadata.namespace\"\n\tfixPath = \"\" \n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tnot metadata.namespace\n\tfailed_path = \"\"\n\tfixPath = {\"path\": \"metadata.namespace\", \"value\": \"YOUR_NAMESPACE\"}\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ConfigMap"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "endpoints-in-default-namespace",
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n    resource := input[_]\n\tresult := is_default_namespace(resource.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is in the 'default' namespace\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t}\n\t}\n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tmetadata.namespace == \"default\"\n\tfailed_path = \"metadata.namespace\"\n\tfixPath = \"\" \n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tnot metadata.namespace\n\tfailed_path = \"\"\n\tfixPath = {\"path\": \"metadata.namespace\", \"value\": \"YOUR_NAMESPACE\"}\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Endpoints"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "persistentvolumeclaim-in-default-namespace",
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n    resource := input[_]\n\tresult := is_default_namespace(resource.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is in the 'default' namespace\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t}\n\t}\n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tmetadata.namespace == \"default\"\n\tfailed_path = \"metadata.namespace\"\n\tfixPath = \"\" \n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tnot metadata.namespace\n\tfailed_path = \"\"\n\tfixPath = {\"path\": \"metadata.namespace\", \"value\": \"YOUR_NAMESPACE\"}\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "PersistentVolumeClaim"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "podtemplate-in-default-namespace",
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n    resource := input[_]\n\tresult := is_default_namespace(resource.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is in the 'default' namespace\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t}\n\t}\n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tmetadata.namespace == \"default\"\n\tfailed_path = \"metadata.namespace\"\n\tfixPath = \"\" \n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tnot metadata.namespace\n\tfailed_path = \"\"\n\tfixPath = {\"path\": \"metadata.namespace\", \"value\": \"YOUR_NAMESPACE\"}\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "PodTemplate"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "replicationcontroller-in-default-namespace",
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n    resource := input[_]\n\tresult := is_default_namespace(resource.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is in the 'default' namespace\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t}\n\t}\n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tmetadata.namespace == \"default\"\n\tfailed_path = \"metadata.namespace\"\n\tfixPath = \"\" \n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tnot metadata.namespace\n\tfailed_path = \"\"\n\tfixPath = {\"path\": \"metadata.namespace\", \"value\": \"YOUR_NAMESPACE\"}\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ReplicationController"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "service-in-default-namespace",
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n    resource := input[_]\n\tresult := is_default_namespace(resource.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is in the 'default' namespace\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t}\n\t}\n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tmetadata.namespace == \"default\"\n\tfailed_path = \"metadata.namespace\"\n\tfixPath = \"\" \n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tnot metadata.namespace\n\tfailed_path = \"\"\n\tfixPath = {\"path\": \"metadata.namespace\", \"value\": \"YOUR_NAMESPACE\"}\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Service"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "serviceaccount-in-default-namespace",
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n    resource := input[_]\n\tresult := is_default_namespace(resource.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is in the 'default' namespace\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t}\n\t}\n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tmetadata.namespace == \"default\"\n\tfailed_path = \"metadata.namespace\"\n\tfixPath = \"\" \n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tnot metadata.namespace\n\tfailed_path = \"\"\n\tfixPath = {\"path\": \"metadata.namespace\", \"value\": \"YOUR_NAMESPACE\"}\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ServiceAccount"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "endpointslice-in-default-namespace",
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n    resource := input[_]\n\tresult := is_default_namespace(resource.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is in the 'default' namespace\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t}\n\t}\n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tmetadata.namespace == \"default\"\n\tfailed_path = \"metadata.namespace\"\n\tfixPath = \"\" \n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tnot metadata.namespace\n\tfailed_path = \"\"\n\tfixPath = {\"path\": \"metadata.namespace\", \"value\": \"YOUR_NAMESPACE\"}\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "discovery.k8s.io"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "EndpointSlice"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "horizontalpodautoscaler-in-default-namespace",
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n    resource := input[_]\n\tresult := is_default_namespace(resource.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is in the 'default' namespace\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t}\n\t}\n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tmetadata.namespace == \"default\"\n\tfailed_path = \"metadata.namespace\"\n\tfixPath = \"\" \n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tnot metadata.namespace\n\tfailed_path = \"\"\n\tfixPath = {\"path\": \"metadata.namespace\", \"value\": \"YOUR_NAMESPACE\"}\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "autoscaling"
              ],
              "apiVersions": [
                "v2"
              ],
              "resources": [
                "HorizontalPodAutoscaler"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "lease-in-default-namespace",
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n    resource := input[_]\n\tresult := is_default_namespace(resource.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is in the 'default' namespace\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t}\n\t}\n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tmetadata.namespace == \"default\"\n\tfailed_path = \"metadata.namespace\"\n\tfixPath = \"\" \n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tnot metadata.namespace\n\tfailed_path = \"\"\n\tfixPath = {\"path\": \"metadata.namespace\", \"value\": \"YOUR_NAMESPACE\"}\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "coordination.k8s.io"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Lease"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "csistoragecapacity-in-default-namespace",
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n    resource := input[_]\n\tresult := is_default_namespace(resource.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is in the 'default' namespace\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t}\n\t}\n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tmetadata.namespace == \"default\"\n\tfailed_path = \"metadata.namespace\"\n\tfixPath = \"\" \n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tnot metadata.namespace\n\tfailed_path = \"\"\n\tfixPath = {\"path\": \"metadata.namespace\", \"value\": \"YOUR_NAMESPACE\"}\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "storage.k8s.io"
              ],
              "apiVersions": [
                "v1beta1"
              ],
              "resources": [
                "CSIStorageCapacity"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "ingress-in-default-namespace",
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n    resource := input[_]\n\tresult := is_default_namespace(resource.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is in the 'default' namespace\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t}\n\t}\n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tmetadata.namespace == \"default\"\n\tfailed_path = \"metadata.namespace\"\n\tfixPath = \"\" \n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tnot metadata.namespace\n\tfailed_path = \"\"\n\tfixPath = {\"path\": \"metadata.namespace\", \"value\": \"YOUR_NAMESPACE\"}\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "networking.k8s.io"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Ingress"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "poddisruptionbudget-in-default-namespace",
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n    resource := input[_]\n\tresult := is_default_namespace(resource.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is in the 'default' namespace\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t}\n\t}\n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tmetadata.namespace == \"default\"\n\tfailed_path = \"metadata.namespace\"\n\tfixPath = \"\" \n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tnot metadata.namespace\n\tfailed_path = \"\"\n\tfixPath = {\"path\": \"metadata.namespace\", \"value\": \"YOUR_NAMESPACE\"}\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "policy"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "PodDisruptionBudget"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        },
        {
          "guid": "",
          "name": "resources-secret-in-default-namespace",
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n    resource := input[_]\n\tresult := is_default_namespace(resource.metadata)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is in the 'default' namespace\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"reviewPaths\": failed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t}\n\t}\n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tmetadata.namespace == \"default\"\n\tfailed_path = \"metadata.namespace\"\n\tfixPath = \"\" \n}\n\nis_default_namespace(metadata) = [failed_path, fixPath] {\n\tnot metadata.namespace\n\tfailed_path = \"\"\n\tfixPath = {\"path\": \"metadata.namespace\", \"value\": \"YOUR_NAMESPACE\"}\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Secret"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 4
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-4.2.1 Minimize the admission of privileged containers",
      "controlID": "C-0213",
      "creationTime": "",
      "description": "Do not generally permit containers to be run with the `securityContext.privileged` flag set to `true`.",
      "remediation": "Create a PSP as described in the Kubernetes documentation, ensuring that the `.spec.privileged` field is omitted or set to `false`.",
      "rules": [
        {
          "guid": "",
          "name": "psp-deny-privileged-container",
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.every\n\ndeny[msga] {\n\t# only fail resources if there all PSPs have privileged set to true\n\t# if even one PSP has privileged set to false, then the rule will not fail\n\tevery psp in input {\n\t\tpsp.kind == \"PodSecurityPolicy\"\n\t\tpsp.spec.privileged == true\n\t}\n\n\t# return al the PSPs that have privileged set to true\n\tpsp := input[_]\n\tpsp.kind == \"PodSecurityPolicy\"\n\tpsp.spec.privileged == true\n\n\tpath := \"spec.privileged\"\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"PodSecurityPolicy: '%v' has privileged set as true.\", [psp.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"deletePaths\": [path],\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\"k8sApiObjects\": [psp]},\n\t}\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "policy"
              ],
              "apiVersions": [
                "v1beta1"
              ],
              "resources": [
                "PodSecurityPolicy"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 8
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-4.2.2 Minimize the admission of containers wishing to share the host process ID namespace",
      "controlID": "C-0214",
      "creationTime": "",
      "description": "Do not generally permit containers to be run with the `hostPID` flag set to true.",
      "remediation": "Create a PSP as described in the Kubernetes documentation, ensuring that the `.spec.hostPID` field is omitted or set to false.",
      "rules": [
        {
          "guid": "",
          "name": "psp-deny-hostpid",
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.every\n\ndeny[msga] {\n\t# only fail resources if there all PSPs have hostPID set to true\n\t# if even one PSP has hostPID set to false, then the rule will not fail\n\tevery psp in input {\n\t\tpsp.kind == \"PodSecurityPolicy\"\n\t\tpsp.spec.hostPID == true\n\t}\n\n\t# return al the PSPs that have hostPID set to true\n\tpsp := input[_]\n\tpsp.kind == \"PodSecurityPolicy\"\n\tpsp.spec.hostPID == true\n\n\tpath := \"spec.hostPID\"\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"PodSecurityPolicy: '%v' has hostPID set as true.\", [psp.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"deletePaths\": [path],\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\"k8sApiObjects\": [psp]},\n\t}\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "policy"
              ],
              "apiVersions": [
                "v1beta1"
              ],
              "resources": [
                "PodSecurityPolicy"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 5
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-4.2.3 Minimize the admission of containers wishing to share the host IPC namespace",
      "controlID": "C-0215",
      "creationTime": "",
      "description": "Do not generally permit containers to be run with the `hostIPC` flag set to true.",
      "remediation": "Create a PSP as described in the Kubernetes documentation, ensuring that the `.spec.hostIPC` field is omitted or set to false.",
      "rules": [
        {
          "guid": "",
          "name": "psp-deny-hostipc",
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.every\n\ndeny[msga] {\n\t# only fail resources if there all PSPs have hostIPC set to true\n\t# if even one PSP has hostIPC set to false, then the rule will not fail\n\tevery psp in input {\n\t\tpsp.kind == \"PodSecurityPolicy\"\n\t\tpsp.spec.hostIPC == true\n\t}\n\n\t# return al the PSPs that have hostIPC set to true\n\tpsp := input[_]\n\tpsp.kind == \"PodSecurityPolicy\"\n\tpsp.spec.hostIPC == true\n\n\tpath := \"spec.hostIPC\"\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"PodSecurityPolicy: '%v' has hostIPC set as true.\", [psp.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"deletePaths\": [path],\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\"k8sApiObjects\": [psp]},\n\t}\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "policy"
              ],
              "apiVersions": [
                "v1beta1"
              ],
              "resources": [
                "PodSecurityPolicy"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 5
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-4.2.4 Minimize the admission of containers wishing to share the host network namespace",
      "controlID": "C-0216",
      "creationTime": "",
      "description": "Do not generally permit containers to be run with the `hostNetwork` flag set to true.",
      "remediation": "Create a PSP as described in the Kubernetes documentation, ensuring that the `.spec.hostNetwork` field is omitted or set to false.",
      "rules": [
        {
          "guid": "",
          "name": "psp-deny-hostnetwork",
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.every\n\ndeny[msga] {\n\t# only fail resources if there all PSPs have hostNetwork set to true\n\t# if even one PSP has hostNetwork set to false, then the rule will not fail\n\tevery psp in input {\n\t\tpsp.kind == \"PodSecurityPolicy\"\n\t\tpsp.spec.hostNetwork == true\n\t}\n\n\t# return al the PSPs that have hostNetwork set to true\n\tpsp := input[_]\n\tpsp.kind == \"PodSecurityPolicy\"\n\tpsp.spec.hostNetwork == true\n\n\tpath := \"spec.hostNetwork\"\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"PodSecurityPolicy: '%v' has hostNetwork set as true.\", [psp.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"deletePaths\": [path],\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\"k8sApiObjects\": [psp]},\n\t}\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "policy"
              ],
              "apiVersions": [
                "v1beta1"
              ],
              "resources": [
                "PodSecurityPolicy"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 5
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-4.2.5 Minimize the admission of containers with allowPrivilegeEscalation",
      "controlID": "C-0217",
      "creationTime": "",
      "description": "Do not generally permit containers to be run with the `allowPrivilegeEscalation` flag set to true.",
      "remediation": "Create a PSP as described in the Kubernetes documentation, ensuring that the `.spec.allowPrivilegeEscalation` field is omitted or set to false.",
      "rules": [
        {
          "guid": "",
          "name": "psp-deny-allowprivilegeescalation",
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.every\n\ndeny[msga] {\n\t# only fail resources if there all PSPs have allowPrivilegeEscalation set to true\n\t# if even one PSP has allowPrivilegeEscalation set to false, then the rule will not fail\n\tevery psp in input {\n\t\tpsp.kind == \"PodSecurityPolicy\"\n\t\tpsp.spec.allowPrivilegeEscalation == true\n\t}\n\n\t# return al the PSPs that have allowPrivilegeEscalation set to true\n\tpsp := input[_]\n\tpsp.kind == \"PodSecurityPolicy\"\n\tpsp.spec.allowPrivilegeEscalation == true\n\n\tpath := \"spec.allowPrivilegeEscalation\"\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"PodSecurityPolicy: '%v' has allowPrivilegeEscalation set as true.\", [psp.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"deletePaths\": [path],\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\"k8sApiObjects\": [psp]},\n\t}\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "policy"
              ],
              "apiVersions": [
                "v1beta1"
              ],
              "resources": [
                "PodSecurityPolicy"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 6
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-4.2.6 Minimize the admission of root containers",
      "controlID": "C-0218",
      "creationTime": "",
      "description": "Do not generally permit containers to be run as the root user.",
      "remediation": "Create a PSP as described in the Kubernetes documentation, ensuring that the `.spec.runAsUser.rule` is set to either `MustRunAsNonRoot` or `MustRunAs` with the range of UIDs not including 0.",
      "rules": [
        {
          "guid": "",
          "name": "psp-deny-root-container",
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.every\n\ndeny[msga] {\n\t# only fail resources if all PSPs permit containers to run as the root user\n\t# if even one PSP restricts containers to run as the root user, then the rule will not fail\n\tevery psp in input {\n\t\tpsp.kind == \"PodSecurityPolicy\"\n\t\tnot deny_run_as_root(psp.spec.runAsUser)\n\t}\n\n\t# return al the PSPs that permit containers to run as the root user\n\tpsp := input[_]\n\tpsp.kind == \"PodSecurityPolicy\"\n\tnot deny_run_as_root(psp.spec.runAsUser)\n\n\tpath := \"spec.runAsUser.rule\"\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"PodSecurityPolicy: '%v' permits containers to run as the root user.\", [psp.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"deletePaths\": [path],\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\"k8sApiObjects\": [psp]},\n\t}\n}\n\ndeny_run_as_root(runAsUser){\n\trunAsUser.rule == \"MustRunAsNonRoot\"\n}\n\ndeny_run_as_root(runAsUser){\n\trunAsUser.rule == \"MustRunAs\"\n\trunAsUser.ranges[_].min > 0\n}",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "policy"
              ],
              "apiVersions": [
                "v1beta1"
              ],
              "resources": [
                "PodSecurityPolicy"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 6
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-4.2.7 Minimize the admission of containers with added capabilities",
      "controlID": "C-0219",
      "creationTime": "",
      "description": "Do not generally permit containers with capabilities assigned beyond the default set.",
      "remediation": "Ensure that `allowedCapabilities` is not present in PSPs for the cluster unless it is set to an empty array.",
      "rules": [
        {
          "guid": "",
          "name": "psp-deny-allowed-capabilities",
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.every\n\ndeny[msga] {\n\t# only fail resources if all PSPs have allowedCapabilities\n\t# if even one PSP has allowedCapabilities as an empty list, then the rule will not fail\n\tevery psp in input {\n\t\tpsp.kind == \"PodSecurityPolicy\"\n\t\tcount(psp.spec.allowedCapabilities) > 0\n\t}\n\n\t# return al the PSPs that have allowedCapabilities\n\tpsp := input[_]\n\tpsp.kind == \"PodSecurityPolicy\"\n\tcount(psp.spec.allowedCapabilities) > 0\n\n\tpath := \"spec.allowedCapabilities\"\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"PodSecurityPolicy: '%v' has allowedCapabilities.\", [psp.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"deletePaths\": [path],\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\"k8sApiObjects\": [psp]},\n\t}\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "policy"
              ],
              "apiVersions": [
                "v1beta1"
              ],
              "resources": [
                "PodSecurityPolicy"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 5
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-3.1.3 Ensure that the kubelet configuration file has permissions set to 644 or more restrictive",
      "controlID": "C-0235",
      "creationTime": "",
      "description": "Ensure that if the kubelet refers to a configuration file with the `--config` argument, that file has permissions of 644 or more restrictive.",
      "remediation": "Run the following command (using the config file location identified in the Audit step)\n\n \n```\nchmod 644 /etc/kubernetes/kubelet/kubelet-config.json\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "ensure-that-the-kubelet-configuration-file-has-permissions-set-to-644-or-more-restrictive",
          "attributes": {
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\nimport data.cautils\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_kubelet_info(obj)\n\n\tfile_obj_path := [\"data\", \"configFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual permissions test\n\tallowed_perms := 420 # == 0o644\n\tnot cautils.unix_permissions_allow(allowed_perms, file.permissions)\n\n\t# Build the message\n\t# filter out irrelevant host-sensor data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\",\n\t])\n\n\talert := sprintf(\"the permissions of %s are too permissive. maximum allowed: %o. actual: %o\", [file.path, allowed_perms, file.permissions])\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chmod %o %s\", [allowed_perms, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"KubeletInfo\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 6
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-3.1.1 Ensure that the kubeconfig file permissions are set to 644 or more restrictive",
      "controlID": "C-0238",
      "creationTime": "",
      "description": "If `kubelet` is running, and if it is configured by a kubeconfig file, ensure that the proxy kubeconfig file has permissions of 644 or more restrictive.",
      "remediation": "Run the below command (based on the file location on your system) on the each worker\nnode. For example,\n\n \n```\nchmod 644 <kubeconfig file>\n\n```",
      "rules": [
        {
          "guid": "",
          "name": "Ensure-that-the-kubeconfig-file-permissions-are-set-to-644-or-more-restrictive",
          "attributes": {
            "hostSensorRule": "true"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.in\n\nimport data.cautils\n\ndeny[msg] {\n\t# Filter out irrelevent resources\n\tobj = input[_]\n\tis_kubelet_info(obj)\n\n\tfile_obj_path := [\"data\", \"kubeConfigFile\"]\n\tfile := object.get(obj, file_obj_path, false)\n\n\t# Actual permissions test. num. configured from Octal (644) to Decimal num.\n\tallowed_perms := 420\n\tnot cautils.unix_permissions_allow(allowed_perms, file.permissions)\n\n\t# Build the message\n\t# filter out irrelevant host-scanner data\n\tobj_filtered := json.filter(obj, [\n\t\tconcat(\"/\", file_obj_path),\n\t\t\"apiVersion\",\n\t\t\"kind\",\n\t\t\"metadata\"\n\t])\n\n\talert := sprintf(\"The permissions of %s are too permissive. maximum allowed: %o. actual: %o\",\n\t[file.path, allowed_perms, file.permissions])\n\n\tmsg := {\n\t\t\"alertMessage\": alert,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": sprintf(\"chmod %o %s\", [allowed_perms, file.path]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"externalObjects\": obj_filtered},\n\t}\n}\n\nis_kubelet_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"KubeletInfo\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": null,
          "dynamicMatch": [
            {
              "apiGroups": [
                "hostdata.kubescape.cloud"
              ],
              "apiVersions": [
                "v1beta0"
              ],
              "resources": [
                "KubeletInfo"
              ]
            }
          ],
          "ruleDependencies": [
            {
              "packageName": "cautils"
            }
          ],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Ensure that the kubeconfig file permissions are set to 644 or more restrictive",
          "remediation": "Run the below command (based on the file location on your system) on the each worker node.\n\n \n```\nchmod 644 <kubeconfig file>\n\n```",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 6
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-5.2.1 Prefer using dedicated AKS Service Accounts",
      "controlID": "C-0239",
      "creationTime": "",
      "description": "Kubernetes workloads should not use cluster node service accounts to authenticate to Azure AKS APIs. Each Kubernetes workload that needs to authenticate to other Azure Web Services using IAM should be provisioned with a dedicated Service account.",
      "remediation": "Azure Active Directory integration\nThe security of AKS clusters can be enhanced with the integration of Azure Active Directory (AD). Built on decades of enterprise identity management, Azure AD is a multi-tenant, cloud-based directory, and identity management service that combines core directory services, application access management, and identity protection. With Azure AD, you can integrate on-premises identities into AKS clusters to provide a single source for account management and security.\n\n Azure Active Directory integration with AKS clusters\n\n With Azure AD-integrated AKS clusters, you can grant users or groups access to Kubernetes resources within a namespace or across the cluster. To obtain a kubectl configuration context, a user can run the az aks get-credentials command. When a user then interacts with the AKS cluster with kubectl, they're prompted to sign in with their Azure AD credentials. This approach provides a single source for user account management and password credentials. The user can only access the resources as defined by the cluster administrator.\n\n Azure AD authentication is provided to AKS clusters with OpenID Connect. OpenID Connect is an identity layer built on top of the OAuth 2.0 protocol. For more information on OpenID Connect, see the Open ID connect documentation. From inside of the Kubernetes cluster, Webhook Token Authentication is used to verify authentication tokens. Webhook token authentication is configured and managed as part of the AKS cluster.",
      "rules": [
        {
          "guid": "",
          "name": "ensure-default-service-accounts-has-only-default-roles",
          "creationTime": "",
          "rule": "package armo_builtins\n\n\n# deny if a default ServiceAccount has rules bound to it that are not defaults. \ndeny[msga] {\n\n    wl := input[_]\n\tspec_template_spec_patterns := {\"RoleBinding\", \"ClusterRoleBinding\"}\n\tspec_template_spec_patterns[wl.kind]\n\n    # filter service accounts\n    wl.subjects[i].kind == \"ServiceAccount\"\n\n    # filter defaults\n    wl.subjects[i].name == \"default\"\n\n    not wl.metadata.labels[\"kubernetes.io/bootstrapping\"] == \"rbac-defaults\"\n\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%s: %v has for ServiceAccount 'default' rules bound to it that are not defaults\", [wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n        \"deletePaths\": [sprintf(\"subjects[%d]\", [i])],\n        \"failedPaths\": [sprintf(\"subjects[%d]\", [i])],\n        \"fixPaths\":[],\n\t\t\"alertScore\": 7,\n        \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                "rbac.authorization.k8s.io"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ClusterRoleBinding",
                "RoleBinding"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 7
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-5.4.4 Ensure Network Policy is Enabled and set as appropriate",
      "controlID": "C-0240",
      "creationTime": "",
      "description": "When you run modern, microservices-based applications in Kubernetes, you often want to control which components can communicate with each other. The principle of least privilege should be applied to how traffic can flow between pods in an Azure Kubernetes Service (AKS) cluster. Let's say you likely want to block traffic directly to back-end applications. The Network Policy feature in Kubernetes lets you define rules for ingress and egress traffic between pods in a cluster.",
      "remediation": "",
      "rules": [
        {
          "guid": "",
          "name": "rule-cni-enabled-aks",
          "creationTime": "",
          "rule": "package armo_builtins\n\n# fails if cni is not enabled like defined in:\n# https://learn.microsoft.com/en-us/azure/aks/use-network-policies#create-an-aks-cluster-and-enable-network-policy\ndeny[msga] {\n\tcluster_describe := input[_]\n\tcluster_describe.apiVersion == \"management.azure.com/v1\"\n\tcluster_describe.kind == \"ClusterDescribe\"\n\tcluster_describe.metadata.provider == \"aks\"\n\tproperties := cluster_describe.data.properties\n\n\tnot cni_enabled_aks(properties)\n\n\tmsga := {\n\t\t\"alertMessage\": \"cni is not enabled\",\n\t\t\"alertScore\": 3,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": [],\n\t\t\"fixCommand\": \"\",\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [],\n\t\t\t\"externalObjects\": cluster_describe,\n\t\t},\n\t}\n}\n\ncni_enabled_aks(properties) {\n\tproperties.networkProfile.networkPlugin == \"azure\"\n\tproperties.networkProfile.networkPolicy == \"azure\"\n}\n\ncni_enabled_aks(properties) {\n\tproperties.networkProfile.networkPlugin == \"azure\"\n\tproperties.networkProfile.networkPolicy == \"calico\"\n}\n\ncni_enabled_aks(properties) {\n\tproperties.networkProfile.networkPlugin == \"kubenet\"\n\tproperties.networkProfile.networkPolicy == \"calico\"\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": null,
          "dynamicMatch": [
            {
              "apiGroups": [
                "management.azure.com"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ClusterDescribe"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": [
            "AKS"
          ]
        }
      ],
      "baseScore": 6
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-5.2.2 Use Azure RBAC for Kubernetes Authorization",
      "controlID": "C-0241",
      "creationTime": "",
      "description": "The ability to manage RBAC for Kubernetes resources from Azure gives you the choice to manage RBAC for the cluster resources either using Azure or native Kubernetes mechanisms.",
      "remediation": "Set Azure RBAC as access system.",
      "rules": [
        {
          "guid": "",
          "name": "ensure-azure-rbac-is-set",
          "creationTime": "",
          "rule": "package armo_builtins\n\n# fails in case Azure RBAC is not set on AKS instance.\ndeny[msga] {\n   \tcluster_describe := input[_]\n\tcluster_describe.apiVersion == \"management.azure.com/v1\"\n\tcluster_describe.kind == \"ClusterDescribe\"\n\tcluster_describe.metadata.provider == \"aks\"\n\tproperties := cluster_describe.data.properties\n\n\tnot isAzureRBACEnabled(properties)\n\n\tmsga := {\n\t\t\"alertMessage\": \"Azure RBAC is not set. Enable it using the command: az aks update -g <resource_group> -n <cluster_name> --enable-azure-rbac\",\n\t\t\"alertScore\": 7,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": [],\n\t\t\"fixCommand\": \"az aks update -g <resource_group> -n <cluster_name> --enable-azure-rbac\",\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"externalObjects\": cluster_describe\n\t\t},\n\t} \n}\n\n# isAzureRBACEnabled check if Azure RBAC is enabled into ClusterDescribe object\n# retrieved from azure cli.\nisAzureRBACEnabled(properties) {\n    properties.aadProfile.enableAzureRBAC == true\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": null,
          "dynamicMatch": [
            {
              "apiGroups": [
                "management.azure.com"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ClusterDescribe"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Azure role-based access control (RBAC) is an authorization system built on Azure Resource Manager that provides fine-grained access management of Azure resources.",
          "remediation": "Enable Azure RBAC on AKS by using the following command: az aks update -g <resource_group> -n <cluster_name> --enable-azure-rbac",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": [
            "AKS"
          ]
        }
      ],
      "baseScore": 7
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-5.6.2 Hostile multi-tenant workloads",
      "controlID": "C-0242",
      "creationTime": "",
      "description": "Currently, Kubernetes environments aren't safe for hostile multi-tenant usage. Extra security features, like Pod Security Policies or Kubernetes RBAC for nodes, efficiently block exploits. For true security when running hostile multi-tenant workloads, only trust a hypervisor. The security domain for Kubernetes becomes the entire cluster, not an individual node.\n\n For these types of hostile multi-tenant workloads, you should use physically isolated clusters. For more information on ways to isolate workloads, see Best practices for cluster isolation in AKS.",
      "remediation": "",
      "rules": [
        {
          "guid": "",
          "name": "rule-hostile-multitenant-workloads",
          "attributes": {
            "actionRequired": "manual review"
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\ndeny[msga] {\n\n\tmsga := {\n\t\t\"alertMessage\": \"Please check it manually.\",\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 2,\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": [],\n         \"alertObject\": {}\n    }\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "ruleDependencies": [],
          "configInputs": [],
          "controlConfigInputs": [],
          "description": "Currently, Kubernetes environments aren't safe for hostile multi-tenant usage. Extra security features, like Pod Security Policies or Kubernetes RBAC for nodes, efficiently block exploits. For true security when running hostile multi-tenant workloads, only trust a hypervisor. The security domain for Kubernetes becomes the entire cluster, not an individual node.",
          "remediation": "Use physically isolated clusters",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 5
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-5.1.1 Ensure Image Vulnerability Scanning using Azure Defender image scanning or a third party provider",
      "controlID": "C-0243",
      "creationTime": "",
      "description": "Scan images being deployed to Azure (AKS) for vulnerabilities.\n\n Vulnerability scanning for images stored in Azure Container Registry is generally available in Azure Security Center. This capability is powered by Qualys, a leading provider of information security.\n\n When you push an image to Container Registry, Security Center automatically scans it, then checks for known vulnerabilities in packages or dependencies defined in the file.\n\n When the scan completes (after about 10 minutes), Security Center provides details and a security classification for each vulnerability detected, along with guidance on how to remediate issues and protect vulnerable attack surfaces.",
      "remediation": "",
      "rules": [
        {
          "guid": "",
          "name": "ensure-image-vulnerability-scanning-using-azure-defender-image-scanning-or-a-third-party-provider",
          "creationTime": "",
          "rule": "package armo_builtins\n\n# fails in case Azure Defender image scanning is not enabled.\ndeny[msga] {\n    cluster_describe := input[_]\n\tcluster_describe.apiVersion == \"management.azure.com/v1\"\n\tcluster_describe.kind == \"ClusterDescribe\"\n\tcluster_describe.metadata.provider == \"aks\"\n\tproperties := cluster_describe.data.properties \n\n    not isAzureImageScanningEnabled(properties)\n\n    msga := {\n\t\t\"alertMessage\": \"Azure Defender image scanning is not enabled.\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": \"az aks update --enable-defender --resource-group <your-resource-group> --name <your-cluster-name>\",\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n            \"externalObjects\": cluster_describe\n        },\n\n\t}\n}\n\n# isAzureImageScanningEnabled check if Azure Defender is enabled into the ClusterDescribe object.\nisAzureImageScanningEnabled(properties) {\n    properties.securityProfile.defender.securityMonitoring.enabled == true\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [],
          "dynamicMatch": [
            {
              "apiGroups": [
                "management.azure.com"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ClusterDescribe"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Scan images being deployed to Azure (AKS) for vulnerabilities. Vulnerability scanning for images stored in Azure Container Registry is generally available in Azure Security Center. This capability is powered by Qualys, a leading provider of information security. When you push an image to Container Registry, Security Center automatically scans it, then checks for known vulnerabilities in packages or dependencies defined in the file. When the scan completes (after about 10 minutes), Security Center provides details and a security classification for each vulnerability detected, along with guidance on how to remediate issues and protect vulnerable attack surfaces.",
          "remediation": "Enable Azure Defender image scanning. Command: az aks update --enable-defender --resource-group <your-resource-group> --name <your-cluster-name>",
          "ruleQuery": "armo_builtin",
          "relevantCloudProviders": [
            "AKS"
          ]
        }
      ],
      "baseScore": 5
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-5.3.1 Ensure Kubernetes Secrets are encrypted",
      "controlID": "C-0244",
      "creationTime": "",
      "description": "Encryption at Rest is a common security requirement. In Azure, organizations can encrypt data at rest without the risk or cost of a custom key management solution. Organizations have the option of letting Azure completely manage Encryption at Rest. Additionally, organizations have various options to closely manage encryption or encryption keys.",
      "remediation": "",
      "rules": [
        {
          "guid": "",
          "name": "secret-etcd-encryption-cloud",
          "creationTime": "",
          "rule": "package armo_builtins\n\n# Check if encryption in etcd in enabled for AKS\ndeny[msga] {\n\tcluster_config := input[_]\n\tcluster_config.apiVersion == \"management.azure.com/v1\"\n\tcluster_config.kind == \"ClusterDescribe\"\n    cluster_config.metadata.provider == \"aks\"\t\n\tconfig = cluster_config.data\n\n\tnot isEncryptedAKS(config)\n\t\n\tmsga := {\n\t\t\"alertMessage\": \"etcd/secret encryption is not enabled\",\n\t\t\"alertScore\": 3,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": \"az aks nodepool add --name hostencrypt --cluster-name <myAKSCluster> --resource-group <myResourceGroup> -s Standard_DS2_v2 -l <myRegion> --enable-encryption-at-host\",\n\t\t\"alertObject\": {\n            \"externalObjects\": cluster_config\n\t\t}\n\t}\n}\n\n\n# Check if encryption in etcd in enabled for EKS\ndeny[msga] {\n\tcluster_config := input[_]\n\tcluster_config.apiVersion == \"eks.amazonaws.com/v1\"\n\tcluster_config.kind == \"ClusterDescribe\"\n    cluster_config.metadata.provider == \"eks\"\t\n\tconfig = cluster_config.data\n\n\tis_not_encrypted_EKS(config)\n    \n\t\n\tmsga := {\n\t\t\"alertMessage\": \"etcd/secret encryption is not enabled\",\n\t\t\"alertScore\": 3,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": \"eksctl utils enable-secrets-encryption --cluster=<cluster> --key-arn=arn:aws:kms:<cluster_region>:<account>:key/<key> --region=<region>\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [],\n            \"externalObjects\": cluster_config\n\t\t}\n\t}\n}\n\n\n\n# Check if encryption in etcd in enabled for GKE\ndeny[msga] {\n\tcluster_config := input[_]\n\tcluster_config.apiVersion == \"container.googleapis.com/v1\"\n\tcluster_config.kind == \"ClusterDescribe\"\n    cluster_config.metadata.provider == \"gke\"\t\n\tconfig := cluster_config.data\n\n\tnot is_encrypted_GKE(config)\n    \n\t\n\tmsga := {\n\t\t\"alertMessage\": \"etcd/secret encryption is not enabled\",\n\t\t\"alertScore\": 3,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"reviewPaths\": [\"data.database_encryption.state\"],\n\t\t\"failedPaths\": [\"data.database_encryption.state\"],\n\t\t\"fixPaths\": [],\n\t\t\"fixCommand\": \"gcloud container clusters update <cluster_name> --region=<compute_region> --database-encryption-key=<key_project_id>/locations/<location>/keyRings/<ring_name>/cryptoKeys/<key_name> --project=<cluster_project_id>\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [],\n            \"externalObjects\": cluster_config\n\t\t}\n\t}\n}\n\nis_encrypted_GKE(config) {\n\t config.database_encryption.state == \"1\"\n}\nis_encrypted_GKE(config) {\n\t config.database_encryption.state == \"ENCRYPTED\"\n}\n\nis_not_encrypted_EKS(cluster_config) {\n\tencryptionConfig := cluster_config.Cluster.EncryptionConfig[_]\n    goodResources := [resource  | resource =   cluster_config.Cluster.EncryptionConfig.Resources[_]; resource == \"secrets\"]\n\tcount(goodResources) == 0\n}\n\nis_not_encrypted_EKS(cluster_config) {\n\tcluster_config.Cluster.EncryptionConfig == null\n}\n\nis_not_encrypted_EKS(cluster_config) {\n\tcount(cluster_config.Cluster.EncryptionConfig) == 0\n}\n\nis_not_encrypted_EKS(cluster_config) {\n\tencryptionConfig := cluster_config.Cluster.EncryptionConfig[_]\n    count(encryptionConfig.Resources) == 0\n}\n\nisEncryptedAKS(cluster_config) {\n\tcluster_config.properties.agentPoolProfiles.enableEncryptionAtHost == true\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "dynamicMatch": [
            {
              "apiGroups": [
                "management.azure.com"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ClusterDescribe"
              ]
            },
            {
              "apiGroups": [
                "eks.amazonaws.com"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ClusterDescribe"
              ]
            },
            {
              "apiGroups": [
                "container.googleapis.com"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ClusterDescribe"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": [
            "AKS",
            "EKS",
            "GKE"
          ]
        }
      ],
      "baseScore": 6
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-5.4.5 Encrypt traffic to HTTPS load balancers with TLS certificates",
      "controlID": "C-0245",
      "creationTime": "",
      "description": "Encrypt traffic to HTTPS load balancers using TLS certificates.",
      "remediation": "",
      "rules": [
        {
          "guid": "",
          "name": "encrypt-traffic-to-https-load-balancers-with-tls-certificates",
          "attributes": {
            "hostSensorRule": "false",
            "imageScanRelated": false
          },
          "creationTime": "",
          "rule": "package armo_builtins\n\n# fails in case of 'Services' of type 'LoadBalancer' are not found.\ndeny[msga] {\n\tsvc := input[_]\n\tsvc.kind == \"Service\"\n\tsvc.spec.type != \"LoadBalancer\"\n\n\tmsga := {\n\t\t\"alertMessage\": \"No LoadBalancer service found.\",\n    \t\"packagename\": \"armo_builtins\",\n    \t\"alertScore\": 7,\n    \t\"failedPaths\": [],\n    \t\"fixPaths\":[],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [svc]\n\t\t}\n\t}\n}\n\n# fails in case 'Service' object has not 'service.beta.kubernetes.io/azure-load-balancer-internal' annotation.\ndeny[msga] {\n\tsvc := input[_]\n\tsvc.kind == \"Service\"\n\tsvc.spec.type == \"LoadBalancer\"\n\tnot svc.metadata.annotations[\"service.beta.kubernetes.io/azure-load-balancer-internal\"]\n\tpath := \"metadata.annotations[service.beta.kubernetes.io/azure-load-balancer-internal]\"\n\n\tmsga := {\n    \t\"alertMessage\": \"Service object LoadBalancer has not 'service.beta.kubernetes.io/azure-load-balancer-internal' annotation.\",\n    \t\"packagename\": \"armo_builtins\",\n    \t\"alertScore\": 7,\n    \t\"failedPaths\": [],\n    \t\"fixPaths\":[{\"path\": path, \"value\": \"true\"}],\n    \t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [svc]\n        }\n    }\n}\n\n# fails in case 'Service' object has annotation 'service.beta.kubernetes.io/azure-load-balancer-internal' != 'true'.\ndeny[msga] {\n\tsvc := input[_]\n\tsvc.kind == \"Service\"\n\tsvc.spec.type == \"LoadBalancer\"\n\tsvc.metadata.annotations[\"service.beta.kubernetes.io/azure-load-balancer-internal\"] != \"true\"\n\tpath := \"metadata.annotations[service.beta.kubernetes.io/azure-load-balancer-internal]\"\n\n\tmsga := {\n    \t\"alertMessage\": \"Service object LoadBalancer has annotation 'service.beta.kubernetes.io/azure-load-balancer-internal' != 'true'.\",\n    \t\"packagename\": \"armo_builtins\",\n    \t\"alertScore\": 7,\n    \t\"failedPaths\": [],\n    \t\"fixPaths\":[{\"path\": path, \"value\": \"true\"}],\n    \t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [svc]\n        }\n    }\n}\n\n# fails in case 'Ingress' object has spec.tls value not set.\ndeny[msga] {\n\tsvc := input[_]\n\tsvc.kind == \"Service\"\n\tsvc.spec.type == \"LoadBalancer\"\n\tsvc.metadata.annotations[\"service.beta.kubernetes.io/azure-load-balancer-internal\"] == \"true\"\n\n\tingress := input[_]\n\tingress.kind == \"Ingress\"\n\tnot isTLSSet(ingress.spec)\n\n\tmsga := {\n    \t\"alertMessage\": \"Ingress object has 'spec.tls' value not set.\",\n    \t\"packagename\": \"armo_builtins\",\n    \t\"alertScore\": 7,\n\t\t\"reviewPaths\": [\"spec.tls\"],\n    \t\"failedPaths\": [\"spec.tls\"],\n    \t\"fixPaths\":[],\n    \t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [ingress]\n        }\n    }\n}\n\n# fails in case 'Ingress' object has annotation 'kubernetes.io/ingress.class' != 'azure/application-gateway'.\ndeny[msga] {\n\tsvc := input[_]\n\tsvc.kind == \"Service\"\n\tsvc.spec.type == \"LoadBalancer\"\n\tsvc.metadata.annotations[\"service.beta.kubernetes.io/azure-load-balancer-internal\"] == \"true\"\n\n\tingress := input[_]\n\tingress.kind == \"Ingress\"\n\tisTLSSet(ingress.spec)\n\tingress.metadata.annotations[\"kubernetes.io/ingress.class\"] != \"azure/application-gateway\"\n\n\tpath := \"metadata.annotations[kubernetes.io/ingress.class]\"\n\n\tmsga := {\n    \t\"alertMessage\": \"Ingress object has annotation 'kubernetes.io/ingress.class' != 'azure/application-gateway'.\",\n    \t\"packagename\": \"armo_builtins\",\n    \t\"alertScore\": 7,\n    \t\"failedPaths\": [],\n    \t\"fixPaths\":[{\"path\": path, \"value\": \"azure/application-gateway\"}],\n        \"fixCommand\": \"\",\n    \t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [ingress]\n        }\n    }\n}\n\nisTLSSet(spec) {\n\tcount(spec.tls) > 0\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [
                ""
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Service"
              ]
            },
            {
              "apiGroups": [
                "networking.k8s.io"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "Ingress"
              ]
            }
          ],
          "ruleDependencies": null,
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Encrypt traffic to HTTPS load balancers using TLS certificates.",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 8
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-5.4.1 Restrict Access to the Control Plane Endpoint",
      "controlID": "C-0247",
      "creationTime": "",
      "description": "Enable Endpoint Private Access to restrict access to the cluster's control plane to only an allowlist of authorized IPs.",
      "remediation": "",
      "rules": [
        {
          "guid": "",
          "name": "restrict-access-to-the-control-plane-endpoint",
          "attributes": {
            "imageScanRelated": false,
            "hostSensorRule": "false"
          },
          "creationTime": "",
          "rule": "\npackage armo_builtins\n\n# fails in case authorizedIPRanges is not set.\ndeny[msga] {\n\tobj := input[_]\n\tobj.apiVersion == \"management.azure.com/v1\"\n\tobj.kind == \"ClusterDescribe\"\n\tobj.metadata.provider == \"aks\"\n\tconfig = obj.data\n\n\tnot isAuthorizedIPRangesSet(config)\n\n\tmsga := {\n    \t\"alertMessage\": \"Parameter 'authorizedIPRanges' was not set.\",\n    \t\"packagename\": \"armo_builtins\",\n    \t\"alertScore\": 7,\n\t\t\"reviewPaths\": [],\n    \t\"failedPaths\": [],\n    \t\"fixPaths\":[],\n        \"fixCommand\": \"az aks update -n '<name>' -g '<resource_group>' --api-server-authorized-ip-ranges '0.0.0.0/32'\",\n    \t\"alertObject\": {\n\t\t\t\"externalObjects\": obj\n        }\n    }\n\n}\n\nisAuthorizedIPRangesSet(config) {\n\tcount(config.properties.apiServerAccessProfile.authorizedIPRanges) > 0\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": null,
          "dynamicMatch": [
            {
              "apiGroups": [
                "management.azure.com"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ClusterDescribe"
              ]
            }
          ],
          "ruleDependencies": null,
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Enable Endpoint Private Access to restrict access to the cluster's control plane to only an allowlist of authorized IPs.",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 8
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-5.4.3 Ensure clusters are created with Private Nodes",
      "controlID": "C-0248",
      "creationTime": "",
      "description": "Disable public IP addresses for cluster nodes, so that they only have private IP addresses. Private Nodes are nodes with no public IP addresses.",
      "remediation": "\n```\naz aks create \\\n--resource-group <private-cluster-resource-group> \\\n--name <private-cluster-name> \\\n--load-balancer-sku standard \\\n--enable-private-cluster \\\n--network-plugin azure \\\n--vnet-subnet-id <subnet-id> \\\n--docker-bridge-address \\\n--dns-service-ip \\\n--service-cidr \n\n```\n Where `--enable-private-cluster` is a mandatory flag for a private cluster.",
      "rules": [
        {
          "guid": "",
          "name": "ensure-clusters-are-created-with-private-nodes",
          "attributes": {
            "hostSensorRule": false,
            "imageScanRelated": false
          },
          "creationTime": "",
          "rule": "\npackage armo_builtins\n\n# fails in case enablePrivateCluster is set to false.\ndeny[msga] {\n\tobj := input[_]\n\tobj.apiVersion == \"management.azure.com/v1\"\n\tobj.kind == \"ClusterDescribe\"\n\tobj.metadata.provider == \"aks\"\n\tconfig = obj.data\n\n\tnot isPrivateClusterEnabled(config)\n\n\tmsga := {\n    \t\"alertMessage\": \"Cluster does not have private nodes.\",\n    \t\"packagename\": \"armo_builtins\",\n    \t\"alertScore\": 7,\n    \t\"failedPaths\": [],\n    \t\"fixPaths\":[],\n        \"fixCommand\": \"az aks create --resource-group <private-cluster-resource-group> --name <private-cluster-name> --load-balancer-sku standard --enable-private-cluster --network-plugin azure --vnet-subnet-id <subnet-id> --docker-bridge-address --dns-service-ip --service-cidr\",\n    \t\"alertObject\": {\n\t\t\"externalObjects\": obj\n        }\n    }\n}\n\nisPrivateClusterEnabled(config) {\n\tconfig.properties.apiServerAccessProfile.enablePrivateCluster == true\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": null,
          "dynamicMatch": [
            {
              "apiGroups": [
                "management.azure.com"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ClusterDescribe"
              ]
            }
          ],
          "ruleDependencies": null,
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Disable public IP addresses for cluster nodes, so that they only have private IP addresses. Private Nodes are nodes with no public IP addresses.",
          "remediation": "az aks create --resource-group <private-cluster-resource-group> --name <private-cluster-name> --load-balancer-sku standard --enable-private-cluster --network-plugin azure --vnet-subnet-id <subnet-id> --docker-bridge-address --dns-service-ip --service-cidr",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 8
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-5.6.1 Restrict untrusted workloads",
      "attributes": {
        "actionRequired": "manual review"
      },
      "controlID": "C-0249",
      "creationTime": "",
      "description": "Restricting unstrusted workloads can be achieved by using ACI along with AKS.\n\n What is ACI?\nACI lets you quickly deploy container instances without additional infrastructure overhead. When you connect with AKS, ACI becomes a secured, logical extension of your AKS cluster. The virtual nodes component, which is based on Virtual Kubelet, is installed in your AKS cluster that presents ACI as a virtual Kubernetes node. Kubernetes can then schedule pods that run as ACI instances through virtual nodes, not as pods on VM nodes directly in your AKS cluster.\n\n Your application requires no modification to use virtual nodes. Deployments can scale across AKS and ACI and with no delay as cluster autoscaler deploys new nodes in your AKS cluster.\n\n Virtual nodes are deployed to an additional subnet in the same virtual network as your AKS cluster. This virtual network configuration allows the traffic between ACI and AKS to be secured. Like an AKS cluster, an ACI instance is a secure, logical compute resource that is isolated from other users.",
      "remediation": "",
      "rules": [
        {
          "guid": "",
          "name": "rule-manual",
          "attributes": {
            "actionRequired": "manual review",
            "hostSensorRule": false,
            "imageScanRelated": false
          },
          "creationTime": "",
          "rule": "\npackage armo_builtins\n\ndeny[msga] {\n\n\tmsga := {\n    \t\"alertMessage\": \"Please check it manually.\",\n    \t\"packagename\": \"armo_builtins\",\n    \t\"alertScore\": 2,\n    \t\"failedPaths\": [],\n    \t\"fixPaths\":[],\n        \"fixCommand\": \"\",\n    \t\"alertObject\": {\n\t\t\t\"k8sObject\": []\n        }\n    }\n}",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "ruleDependencies": null,
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Due to the difficulty of performing a good check, the review is left manual to the user.",
          "remediation": "",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 5
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-5.1.2 Minimize cluster access to read-only for Azure Container Registry (ACR)",
      "controlID": "C-0250",
      "creationTime": "",
      "description": "Configure the Cluster Service Account with Storage Object Viewer Role to only allow read-only access to Azure Container Registry (ACR)",
      "remediation": "",
      "rules": [
        {
          "guid": "",
          "name": "ensure-service-principle-has-read-only-permissions",
          "creationTime": "",
          "rule": "package armo_builtins\n\nimport future.keywords.every\n\n# deny if servicePrincipal has permissions that are not read-only\ndeny[msga] {\n\tresources := input[_]\n\tresources.kind == \"ListEntitiesForPolicies\"\n\tresources.metadata.provider == \"aks\"\n\n\troleAssignment := resources.data.roleAssignments[_]\n\troleAssignment.properties.principalType == \"ServicePrincipal\"\n\n\tpolicies := input[_]\n\tpolicies.kind == \"PolicyVersion\"\n\tpolicies.metadata.provider == \"aks\"\n\n\tpolicy := policies.data.roleDefinitions[_]\n\tpolicy.id == roleAssignment.properties.roleDefinitionId\n\n\t# check if policy has at least one action that is not read\n\tsome action in policy.properties.permissions[_].actions\n\t\tnot endswith(action, \"read\")\n\n\tmsga := {\n\t\t\"alertMessage\": \"ServicePrincipal has permissions that are not read-only to ACR.\",\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"externalObjects\": resources\n\t\t}\n\t}\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": null,
          "dynamicMatch": [
            {
              "apiGroups": [
                "management.azure.com"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ListEntitiesForPolicies"
              ]
            },
            {
              "apiGroups": [
                "management.azure.com"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "PolicyVersion"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": [
            "AKS"
          ]
        }
      ],
      "baseScore": 6
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-5.1.3 Minimize user access to Azure Container Registry (ACR)",
      "controlID": "C-0251",
      "creationTime": "",
      "description": "Restrict user access to Azure Container Registry (ACR), limiting interaction with build images to only authorized personnel and service accounts.",
      "remediation": "Azure Container Registry\nIf you use Azure Container Registry (ACR) as your container image store, you need to grant permissions to the service principal for your AKS cluster to read and pull images. Currently, the recommended configuration is to use the az aks create or az aks update command to integrate with a registry and assign the appropriate role for the service principal. For detailed steps, see Authenticate with Azure Container Registry from Azure Kubernetes Service.\n\n To avoid needing an Owner or Azure account administrator role, you can configure a service principal manually or use an existing service principal to authenticate ACR from AKS. For more information, see ACR authentication with service principals or Authenticate from Kubernetes with a pull secret.",
      "rules": [
        {
          "guid": "",
          "name": "list-role-definitions-in-acr",
          "creationTime": "",
          "rule": "package armo_builtins\n\n# return ListEntitiesForPolicies resource in azure\ndeny[msg] {\n\tresources := input[_]\n\tresources.kind == \"ListEntitiesForPolicies\"\n\tresources.apiVersion == \"management.azure.com/v1\"\n\tresources.metadata.provider == \"aks\"\n\n\tmsg := {\n\t\t\"alertMessage\": \"\",\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"externalObjects\": resources\n\t\t}\n\t}\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": null,
          "dynamicMatch": [
            {
              "apiGroups": [
                "management.azure.com"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ListEntitiesForPolicies"
              ]
            }
          ],
          "ruleDependencies": [],
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "",
          "remediation": "",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": [
            "AKS"
          ]
        }
      ],
      "baseScore": 6
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-5.4.2 Ensure clusters are created with Private Endpoint Enabled and Public Access Disabled",
      "controlID": "C-0252",
      "creationTime": "",
      "description": "Disable access to the Kubernetes API from outside the node network if it is not required.",
      "remediation": "To use a private endpoint, create a new private endpoint in your virtual network then create a link between your virtual network and a new private DNS zone",
      "rules": [
        {
          "guid": "",
          "name": "ensure-clusters-are-created-with-private-endpoint-enabled-and-public-access-disabled",
          "attributes": {
            "hostSensorRule": "false",
            "imageScanRelated": false
          },
          "creationTime": "",
          "rule": "\npackage armo_builtins\n\n# fails in case privateEndpoint.id parameter is not found on ClusterDescribe\ndeny[msga] {\n\tobj := input[_]\n\tobj.apiVersion == \"management.azure.com/v1\"\n\tobj.kind == \"ClusterDescribe\"\n\tobj.metadata.provider == \"aks\"\n\tconfig = obj.data\n\n\tnot isPrivateEndpointEnabled(config)\n\n\tmsga := {\n    \t\"alertMessage\": \"Private endpoint not enabled.\",\n    \t\"packagename\": \"armo_builtins\",\n    \t\"alertScore\": 7,\n    \t\"failedPaths\": [],\n    \t\"fixPaths\":[],\n        \"fixCommand\": \"\",\n    \t\"alertObject\": {\n\t\t\t\"externalObjects\": obj\n        }\n    }\n}\n\nisPrivateEndpointEnabled(config) {\n\tconfig.properties.privateEndpoint.id\n}\n",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": null,
          "dynamicMatch": [
            {
              "apiGroups": [
                "management.azure.com"
              ],
              "apiVersions": [
                "v1"
              ],
              "resources": [
                "ClusterDescribe"
              ]
            }
          ],
          "ruleDependencies": null,
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Disable access to the Kubernetes API from outside the node network if it is not required.",
          "remediation": "To use a private endpoint, create a new private endpoint in your virtual network then create a link between your virtual network and a new private DNS zone",
          "ruleQuery": "armo_builtins",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 8
    },
    {
      "rulesIDs": [
        ""
      ],
      "guid": "",
      "name": "CIS-2.1.1 Enable audit Logs",
      "controlID": "C-0254",
      "creationTime": "",
      "description": "With Azure Kubernetes Service (AKS), the control plane components such as the kube-apiserver and kube-controller-manager are provided as a managed service. You create and manage the nodes that run the kubelet and container runtime, and deploy your applications through the managed Kubernetes API server. To help troubleshoot your application and services, you may need to view the logs generated by these control plane components.\n\n To help collect and review data from multiple sources, Azure Monitor logs provides a query language and analytics engine that provides insights to your environment. A workspace is used to collate and analyze the data, and can integrate with other Azure services such as Application Insights and Security Center.",
      "remediation": "Azure audit logs are enabled and managed in the Azure portal. To enable log collection for the Kubernetes master components in your AKS cluster, open the Azure portal in a web browser and complete the following steps:\n\n 1. Select the resource group for your AKS cluster, such as myResourceGroup. Don't select the resource group that contains your individual AKS cluster resources, such as MC\\_myResourceGroup\\_myAKSCluster\\_eastus.\n2. On the left-hand side, choose Diagnostic settings.\n3. Select your AKS cluster, such as myAKSCluster, then choose to Add diagnostic setting.\n4. Enter a name, such as myAKSClusterLogs, then select the option to Send to Log Analytics.\n5. Select an existing workspace or create a new one. If you create a workspace, provide a workspace name, a resource group, and a location.\n6. In the list of available logs, select the logs you wish to enable. For this example, enable the kube-audit and kube-audit-admin logs. Common logs include the kube-apiserver, kube-controller-manager, and kube-scheduler. You can return and change the collected logs once Log Analytics workspaces are enabled.\n7. When ready, select Save to enable collection of the selected logs.",
      "rules": [
        {
          "guid": "",
          "name": "rule-manual",
          "attributes": {
            "hostSensorRule": false,
            "imageScanRelated": false,
            "actionRequired": "manual review"
          },
          "creationTime": "",
          "rule": "\npackage armo_builtins\n\ndeny[msga] {\n\n\tmsga := {\n    \t\"alertMessage\": \"Please check it manually.\",\n    \t\"packagename\": \"armo_builtins\",\n    \t\"alertScore\": 2,\n    \t\"failedPaths\": [],\n    \t\"fixPaths\":[],\n        \"fixCommand\": \"\",\n    \t\"alertObject\": {\n\t\t\t\"k8sObject\": []\n        }\n    }\n}",
          "resourceEnumerator": "",
          "ruleLanguage": "Rego",
          "match": [
            {
              "apiGroups": [],
              "apiVersions": [],
              "resources": []
            }
          ],
          "ruleDependencies": null,
          "configInputs": null,
          "controlConfigInputs": null,
          "description": "Due to the difficulty of performing a good check, the review is left manual to the user.",
          "remediation": "",
          "ruleQuery": "",
          "relevantCloudProviders": null
        }
      ],
      "baseScore": 5
    }
  ],
  "controlsIDs": [
    "C-0078",
    "C-0088",
    "C-0167",
    "C-0171",
    "C-0172",
    "C-0173",
    "C-0174",
    "C-0175",
    "C-0176",
    "C-0177",
    "C-0178",
    "C-0179",
    "C-0180",
    "C-0182",
    "C-0183",
    "C-0185",
    "C-0186",
    "C-0187",
    "C-0188",
    "C-0189",
    "C-0190",
    "C-0201",
    "C-0205",
    "C-0206",
    "C-0207",
    "C-0208",
    "C-0209",
    "C-0211",
    "C-0212",
    "C-0213",
    "C-0214",
    "C-0215",
    "C-0216",
    "C-0217",
    "C-0218",
    "C-0219",
    "C-0235",
    "C-0238",
    "C-0239",
    "C-0240",
    "C-0241",
    "C-0242",
    "C-0243",
    "C-0244",
    "C-0245",
    "C-0247",
    "C-0248",
    "C-0249",
    "C-0250",
    "C-0251",
    "C-0252",
    "C-0254"
  ],
  "subSections": {
    "3": {
      "guid": "",
      "name": "Worker Nodes",
      "id": "3",
      "subSections": {
        "1": {
          "guid": "",
          "name": "Worker Node Configuration Files",
          "id": "3.1",
          "controlsIDs": [
            "C-0167",
            "C-0171",
            "C-0235",
            "C-0238"
          ]
        },
        "2": {
          "guid": "",
          "name": "Kubelet",
          "id": "3.2",
          "controlsIDs": [
            "C-0172",
            "C-0173",
            "C-0174",
            "C-0175",
            "C-0176",
            "C-0177",
            "C-0178",
            "C-0179",
            "C-0180",
            "C-0182",
            "C-0183"
          ]
        }
      }
    },
    "4": {
      "guid": "",
      "name": "Policies",
      "id": "4",
      "subSections": {
        "6": {
          "guid": "",
          "name": "Extensible Admission Control",
          "id": "4.6"
        },
        "7": {
          "guid": "",
          "name": "General Policies",
          "id": "4.7",
          "controlsIDs": [
            "C-0209",
            "C-0211",
            "C-0212"
          ]
        },
        "1": {
          "guid": "",
          "name": "RBAC and Service Accounts",
          "id": "4.1",
          "controlsIDs": [
            "C-0185",
            "C-0186",
            "C-0187",
            "C-0188",
            "C-0189",
            "C-0190"
          ]
        },
        "2": {
          "guid": "",
          "name": "Pod Security Standards",
          "id": "4.2",
          "controlsIDs": [
            "C-0201",
            "C-0213",
            "C-0214",
            "C-0215",
            "C-0216",
            "C-0217",
            "C-0218",
            "C-0219"
          ]
        },
        "3": {
          "guid": "",
          "name": "Azure Policy / OPA",
          "id": "4.3"
        },
        "4": {
          "guid": "",
          "name": "CNI Plugin",
          "id": "4.4",
          "controlsIDs": [
            "C-0205",
            "C-0206"
          ]
        },
        "5": {
          "guid": "",
          "name": "Secrets Management",
          "id": "4.5",
          "controlsIDs": [
            "C-0207",
            "C-0208"
          ]
        }
      }
    },
    "5": {
      "guid": "",
      "name": "Managed services",
      "id": "5",
      "subSections": {
        "4": {
          "guid": "",
          "name": "Cluster Networking",
          "id": "5.4",
          "controlsIDs": [
            "C-0240",
            "C-0245",
            "C-0247",
            "C-0248",
            "C-0252"
          ]
        },
        "5": {
          "guid": "",
          "name": "Authentication and Authorization",
          "id": "5.5",
          "controlsIDs": [
            "C-0088"
          ]
        },
        "6": {
          "guid": "",
          "name": "Other Cluster Configurations",
          "id": "5.6",
          "controlsIDs": [
            "C-0242",
            "C-0249"
          ]
        },
        "1": {
          "guid": "",
          "name": "Image Registry and Image Scanning",
          "id": "5.1",
          "controlsIDs": [
            "C-0078",
            "C-0243",
            "C-0250",
            "C-0251"
          ]
        },
        "2": {
          "guid": "",
          "name": "Access and identity options for Azure Kubernetes Service (AKS)",
          "id": "5.2",
          "controlsIDs": [
            "C-0239",
            "C-0241"
          ]
        },
        "3": {
          "guid": "",
          "name": "Key Management Service (KMS)",
          "id": "5.3",
          "controlsIDs": [
            "C-0244"
          ]
        }
      }
    },
    "2": {
      "guid": "",
      "name": "Master (Control Plane) Configuration",
      "id": "2",
      "subSections": {
        "1": {
          "guid": "",
          "name": "Logging",
          "id": "2.1",
          "controlsIDs": [
            "C-0254"
          ]
        }
      }
    }
  }
}